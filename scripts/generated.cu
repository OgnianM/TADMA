
using namespace tadma;
using ALLOCATOR = Allocator<kCUDA>;

struct Model {
    std::ifstream bin;

    Model(const std::string& weights) : bin(weights) { bin.close(); }

    Tensor<float, ALLOCATOR, Sequence<30522,768>> bert_embeddings_word_embeddings_weight = Tensor<float, ALLOCATOR, Sequence<30522,768>>(bin, 0ULL);
    Tensor<float, ALLOCATOR, Sequence<512,768>> bert_embeddings_position_embeddings_weight = Tensor<float, ALLOCATOR, Sequence<512,768>>(bin, 93763584ULL);
    Tensor<float, ALLOCATOR, Sequence<2,768>> bert_embeddings_token_type_embeddings_weight = Tensor<float, ALLOCATOR, Sequence<2,768>>(bin, 95336448ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_embeddings_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95342592ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_embeddings_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95345664ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_0_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95348736ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_0_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95351808ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_0_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95354880ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_0_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95357952ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_0_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95361024ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_0_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95364096ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_0_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95367168ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_0_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95379456ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_0_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95382528ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_0_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95385600ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_1_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95388672ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_1_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95391744ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_1_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95394816ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_1_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95397888ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_1_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95400960ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_1_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95404032ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_1_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95407104ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_1_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95419392ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_1_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95422464ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_1_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95425536ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_2_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95428608ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_2_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95431680ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_2_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95434752ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_2_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95437824ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_2_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95440896ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_2_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95443968ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_2_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95447040ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_2_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95459328ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_2_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95462400ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_2_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95465472ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_3_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95468544ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_3_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95471616ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_3_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95474688ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_3_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95477760ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_3_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95480832ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_3_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95483904ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_3_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95486976ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_3_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95499264ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_3_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95502336ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_3_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95505408ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_4_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95508480ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_4_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95511552ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_4_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95514624ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_4_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95517696ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_4_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95520768ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_4_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95523840ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_4_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95526912ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_4_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95539200ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_4_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95542272ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_4_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95545344ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_5_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95548416ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_5_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95551488ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_5_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95554560ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_5_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95557632ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_5_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95560704ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_5_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95563776ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_5_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95566848ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_5_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95579136ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_5_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95582208ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_5_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95585280ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_6_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95588352ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_6_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95591424ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_6_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95594496ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_6_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95597568ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_6_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95600640ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_6_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95603712ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_6_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95606784ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_6_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95619072ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_6_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95622144ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_6_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95625216ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_7_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95628288ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_7_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95631360ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_7_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95634432ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_7_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95637504ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_7_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95640576ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_7_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95643648ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_7_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95646720ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_7_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95659008ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_7_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95662080ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_7_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95665152ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_8_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95668224ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_8_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95671296ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_8_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95674368ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_8_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95677440ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_8_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95680512ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_8_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95683584ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_8_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95686656ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_8_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95698944ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_8_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95702016ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_8_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95705088ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_9_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95708160ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_9_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95711232ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_9_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95714304ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_9_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95717376ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_9_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95720448ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_9_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95723520ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_9_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95726592ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_9_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95738880ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_9_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95741952ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_9_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95745024ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_10_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95748096ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_10_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95751168ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_10_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95754240ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_10_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95757312ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_10_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95760384ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_10_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95763456ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_10_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95766528ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_10_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95778816ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_10_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95781888ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_10_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95784960ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_11_attention_self_query_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95788032ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_11_attention_self_key_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95791104ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_11_attention_self_value_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95794176ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_11_attention_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95797248ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_11_attention_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95800320ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_11_attention_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95803392ULL);
    Tensor<float, ALLOCATOR, Sequence<3072>> bert_encoder_layer_11_intermediate_dense_bias = Tensor<float, ALLOCATOR, Sequence<3072>>(bin, 95806464ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_11_output_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95818752ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_11_output_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95821824ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> bert_encoder_layer_11_output_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95824896ULL);
    Tensor<float, ALLOCATOR, Sequence<30522>> cls_predictions_bias = Tensor<float, ALLOCATOR, Sequence<30522>>(bin, 95827968ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> cls_predictions_transform_dense_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95950056ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> cls_predictions_transform_LayerNorm_weight = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95953128ULL);
    Tensor<float, ALLOCATOR, Sequence<768>> cls_predictions_transform_LayerNorm_bias = Tensor<float, ALLOCATOR, Sequence<768>>(bin, 95956200ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1899 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 95959272ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1902 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 98318568ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1905 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 100677864ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1909 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 103037160ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_1910 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 105396456ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_1911 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 114833640ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1912 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 124270824ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1915 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 126630120ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1918 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 128989416ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1922 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 131348712ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_1923 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 133708008ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_1924 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 143145192ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1925 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 152582376ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1928 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 154941672ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1931 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 157300968ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1935 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 159660264ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_1936 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 162019560ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_1937 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 171456744ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1938 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 180893928ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1941 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 183253224ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1944 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 185612520ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1948 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 187971816ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_1949 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 190331112ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_1950 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 199768296ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1951 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 209205480ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1954 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 211564776ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1957 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 213924072ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1961 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 216283368ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_1962 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 218642664ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_1963 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 228079848ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1964 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 237517032ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1967 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 239876328ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1970 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 242235624ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1974 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 244594920ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_1975 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 246954216ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_1976 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 256391400ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1977 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 265828584ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1980 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 268187880ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1983 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 270547176ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1987 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 272906472ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_1988 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 275265768ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_1989 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 284702952ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1990 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 294140136ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1993 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 296499432ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_1996 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 298858728ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2000 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 301218024ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_2001 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 303577320ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_2002 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 313014504ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2003 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 322451688ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2006 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 324810984ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2009 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 327170280ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2013 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 329529576ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_2014 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 331888872ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_2015 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 341326056ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2016 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 350763240ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2019 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 353122536ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2022 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 355481832ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2026 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 357841128ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_2027 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 360200424ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_2028 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 369637608ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2029 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 379074792ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2032 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 381434088ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2035 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 383793384ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2039 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 386152680ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_2040 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 388511976ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_2041 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 397949160ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2042 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 407386344ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2045 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 409745640ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2048 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 412104936ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2052 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 414464232ULL);
    Tensor<float, ALLOCATOR, Sequence<768,3072>> onnx_MatMul_2053 = Tensor<float, ALLOCATOR, Sequence<768,3072>>(bin, 416823528ULL);
    Tensor<float, ALLOCATOR, Sequence<3072,768>> onnx_MatMul_2054 = Tensor<float, ALLOCATOR, Sequence<3072,768>>(bin, 426260712ULL);
    Tensor<float, ALLOCATOR, Sequence<768,768>> onnx_MatMul_2055 = Tensor<float, ALLOCATOR, Sequence<768,768>>(bin, 435697896ULL);
    static constexpr auto _bert_Constant_output_0 = 1;
    using onnx_Slice_209_sequence = Sequence<0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511>;
    Tensor<TYPE(onnx_Slice_209_sequence::Array()[0]), ConstexprAllocator<onnx_Slice_209_sequence>, Sequence<512>> onnx_Slice_209 = {};
    static constexpr auto _bert_embeddings_Constant_output_0 = 1;
    static constexpr auto _bert_embeddings_Constant_1_output_0 = 0;
    static constexpr auto _bert_embeddings_Constant_2_output_0 = 0;
    static constexpr auto _bert_embeddings_Constant_3_output_0 = 1;
    static constexpr auto _bert_embeddings_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_embeddings_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_Constant_1_output_0 = 0;
    static constexpr auto _bert_Constant_2_output_0 = 1;
    static constexpr auto _bert_Constant_3_output_0 = 1;
    static constexpr auto _bert_Constant_4_output_0 = 2;
    static constexpr auto _bert_Constant_5_output_0 = 0;
    static constexpr auto _bert_Constant_6_output_0 = 1;
    static constexpr auto _bert_Constant_7_output_0 = 0;
    static constexpr auto _bert_Constant_8_output_0 = 0;
    static constexpr auto _bert_Constant_9_output_0 = -1;
    static constexpr auto _bert_ConstantOfShape_output_0 = 1;
    static constexpr auto _bert_Constant_10_output_0 = -1;
    static constexpr auto _bert_Constant_11_output_0 = 1.0;
    static constexpr auto _bert_Constant_12_output_0 = -3.4028234663852886e+38;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_288 = 0;
    static constexpr auto onnx_Unsqueeze_290 = 0;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_308 = 0;
    static constexpr auto onnx_Unsqueeze_310 = 0;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_327 = 0;
    static constexpr auto onnx_Unsqueeze_329 = 0;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_358 = 0;
    static constexpr auto onnx_Unsqueeze_360 = 0;
    static constexpr auto _bert_encoder_layer_0_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_0_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_0_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_0_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_0_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_0_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_0_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_0_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_422 = 0;
    static constexpr auto onnx_Unsqueeze_424 = 0;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_442 = 0;
    static constexpr auto onnx_Unsqueeze_444 = 0;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_461 = 0;
    static constexpr auto onnx_Unsqueeze_463 = 0;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_491 = 0;
    static constexpr auto onnx_Unsqueeze_493 = 0;
    static constexpr auto _bert_encoder_layer_1_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_1_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_1_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_1_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_1_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_1_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_1_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_1_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_555 = 0;
    static constexpr auto onnx_Unsqueeze_557 = 0;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_575 = 0;
    static constexpr auto onnx_Unsqueeze_577 = 0;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_594 = 0;
    static constexpr auto onnx_Unsqueeze_596 = 0;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_624 = 0;
    static constexpr auto onnx_Unsqueeze_626 = 0;
    static constexpr auto _bert_encoder_layer_2_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_2_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_2_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_2_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_2_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_2_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_2_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_2_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_688 = 0;
    static constexpr auto onnx_Unsqueeze_690 = 0;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_708 = 0;
    static constexpr auto onnx_Unsqueeze_710 = 0;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_727 = 0;
    static constexpr auto onnx_Unsqueeze_729 = 0;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_757 = 0;
    static constexpr auto onnx_Unsqueeze_759 = 0;
    static constexpr auto _bert_encoder_layer_3_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_3_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_3_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_3_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_3_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_3_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_3_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_3_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_821 = 0;
    static constexpr auto onnx_Unsqueeze_823 = 0;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_841 = 0;
    static constexpr auto onnx_Unsqueeze_843 = 0;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_860 = 0;
    static constexpr auto onnx_Unsqueeze_862 = 0;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_890 = 0;
    static constexpr auto onnx_Unsqueeze_892 = 0;
    static constexpr auto _bert_encoder_layer_4_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_4_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_4_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_4_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_4_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_4_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_4_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_4_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_954 = 0;
    static constexpr auto onnx_Unsqueeze_956 = 0;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_974 = 0;
    static constexpr auto onnx_Unsqueeze_976 = 0;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_993 = 0;
    static constexpr auto onnx_Unsqueeze_995 = 0;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_1023 = 0;
    static constexpr auto onnx_Unsqueeze_1025 = 0;
    static constexpr auto _bert_encoder_layer_5_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_5_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_5_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_5_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_5_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_5_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_5_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_5_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1087 = 0;
    static constexpr auto onnx_Unsqueeze_1089 = 0;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1107 = 0;
    static constexpr auto onnx_Unsqueeze_1109 = 0;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1126 = 0;
    static constexpr auto onnx_Unsqueeze_1128 = 0;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_1156 = 0;
    static constexpr auto onnx_Unsqueeze_1158 = 0;
    static constexpr auto _bert_encoder_layer_6_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_6_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_6_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_6_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_6_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_6_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_6_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_6_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1220 = 0;
    static constexpr auto onnx_Unsqueeze_1222 = 0;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1240 = 0;
    static constexpr auto onnx_Unsqueeze_1242 = 0;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1259 = 0;
    static constexpr auto onnx_Unsqueeze_1261 = 0;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_1289 = 0;
    static constexpr auto onnx_Unsqueeze_1291 = 0;
    static constexpr auto _bert_encoder_layer_7_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_7_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_7_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_7_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_7_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_7_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_7_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_7_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1353 = 0;
    static constexpr auto onnx_Unsqueeze_1355 = 0;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1373 = 0;
    static constexpr auto onnx_Unsqueeze_1375 = 0;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1392 = 0;
    static constexpr auto onnx_Unsqueeze_1394 = 0;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_1422 = 0;
    static constexpr auto onnx_Unsqueeze_1424 = 0;
    static constexpr auto _bert_encoder_layer_8_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_8_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_8_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_8_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_8_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_8_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_8_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_8_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1486 = 0;
    static constexpr auto onnx_Unsqueeze_1488 = 0;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1506 = 0;
    static constexpr auto onnx_Unsqueeze_1508 = 0;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1525 = 0;
    static constexpr auto onnx_Unsqueeze_1527 = 0;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_1555 = 0;
    static constexpr auto onnx_Unsqueeze_1557 = 0;
    static constexpr auto _bert_encoder_layer_9_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_9_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_9_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_9_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_9_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_9_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_9_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_9_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1619 = 0;
    static constexpr auto onnx_Unsqueeze_1621 = 0;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1639 = 0;
    static constexpr auto onnx_Unsqueeze_1641 = 0;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1658 = 0;
    static constexpr auto onnx_Unsqueeze_1660 = 0;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_1688 = 0;
    static constexpr auto onnx_Unsqueeze_1690 = 0;
    static constexpr auto _bert_encoder_layer_10_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_10_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_10_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_10_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_10_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_10_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_10_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_10_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_output_0 = 0;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_1_output_0 = 1;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_2_output_0 = 0;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_3_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1752 = 0;
    static constexpr auto onnx_Unsqueeze_1754 = 0;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_4_output_0 = 12;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_5_output_0 = 64;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_6_output_0 = 0;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_7_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1772 = 0;
    static constexpr auto onnx_Unsqueeze_1774 = 0;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_8_output_0 = 12;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_9_output_0 = 64;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_10_output_0 = 0;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_11_output_0 = 1;
    static constexpr auto onnx_Unsqueeze_1791 = 0;
    static constexpr auto onnx_Unsqueeze_1793 = 0;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_12_output_0 = 12;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_13_output_0 = 64;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_14_output_0 = -1;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_15_output_0 = 9223372036854775807;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_16_output_0 = 1.0;
    static constexpr auto onnx_Unsqueeze_1821 = 0;
    static constexpr auto onnx_Unsqueeze_1823 = 0;
    static constexpr auto _bert_encoder_layer_11_attention_self_Constant_17_output_0 = 768;
    static constexpr auto _bert_encoder_layer_11_attention_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_11_attention_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _bert_encoder_layer_11_intermediate_intermediate_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _bert_encoder_layer_11_intermediate_intermediate_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _bert_encoder_layer_11_intermediate_intermediate_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _bert_encoder_layer_11_output_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _bert_encoder_layer_11_output_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;
    static constexpr auto _cls_predictions_transform_transform_act_fn_Constant_output_0 = 1.4142135381698608;
    static constexpr auto _cls_predictions_transform_transform_act_fn_Constant_1_output_0 = 1.0;
    static constexpr auto _cls_predictions_transform_transform_act_fn_Constant_2_output_0 = 0.5;
    static constexpr auto _cls_predictions_transform_LayerNorm_Constant_output_0 = 2.0;
    static constexpr auto _cls_predictions_transform_LayerNorm_Constant_1_output_0 = 9.999999960041972e-13;

    template<int64_t batch_size, int64_t sequence_length>
    auto infer(Tensor<int64_t, ALLOCATOR, Sequence<batch_size,sequence_length>> input_ids, Tensor<int64_t, ALLOCATOR, Sequence<batch_size,sequence_length>> attention_mask, Tensor<int64_t, ALLOCATOR, Sequence<batch_size,sequence_length>> token_type_ids) {
    auto _bert_Shape_output_0 = shape(input_ids);
    auto _bert_Gather_output_0 = gather(_bert_Shape_output_0, _bert_Constant_output_0);
    auto _bert_embeddings_Unsqueeze_output_0 = unsqueeze<_bert_embeddings_Constant_2_output_0>(_bert_Gather_output_0);
    auto _bert_embeddings_Slice_output_0 = onnx_Slice_209.template slice<_bert_embeddings_Constant_1_output_0,_bert_embeddings_Unsqueeze_output_0,_bert_embeddings_Constant_output_0,_bert_embeddings_Constant_3_output_0>();
    auto _bert_embeddings_word_embeddings_Gather_output_0 = gather(bert_embeddings_word_embeddings_weight, input_ids);
    auto _bert_embeddings_token_type_embeddings_Gather_output_0 = gather(bert_embeddings_token_type_embeddings_weight, token_type_ids);
    auto _bert_embeddings_Add_output_0 = _bert_embeddings_word_embeddings_Gather_output_0 + _bert_embeddings_token_type_embeddings_Gather_output_0;
    auto _bert_embeddings_position_embeddings_Gather_output_0 = gather(bert_embeddings_position_embeddings_weight, _bert_embeddings_Slice_output_0);
    auto _bert_embeddings_Add_1_output_0 = _bert_embeddings_Add_output_0 + _bert_embeddings_position_embeddings_Gather_output_0;
    auto _bert_embeddings_LayerNorm_ReduceMean_output_0 = _bert_embeddings_Add_1_output_0.template mean<0>();
    auto _bert_embeddings_LayerNorm_Sub_output_0 = _bert_embeddings_Add_1_output_0 - _bert_embeddings_LayerNorm_ReduceMean_output_0;
    auto _bert_embeddings_LayerNorm_Pow_output_0 = pow<false>(_bert_embeddings_LayerNorm_Sub_output_0, _bert_embeddings_LayerNorm_Constant_output_0);
    auto _bert_embeddings_LayerNorm_ReduceMean_1_output_0 = _bert_embeddings_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_embeddings_LayerNorm_Add_output_0 = _bert_embeddings_LayerNorm_ReduceMean_1_output_0 + _bert_embeddings_LayerNorm_Constant_1_output_0;
    auto _bert_embeddings_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_embeddings_LayerNorm_Add_output_0);
    auto _bert_embeddings_LayerNorm_Div_output_0 = _bert_embeddings_LayerNorm_Sub_output_0 / _bert_embeddings_LayerNorm_Sqrt_output_0;
    auto _bert_embeddings_LayerNorm_Mul_output_0 = _bert_embeddings_LayerNorm_Div_output_0 * bert_embeddings_LayerNorm_weight;
    auto _bert_embeddings_LayerNorm_Add_1_output_0 = _bert_embeddings_LayerNorm_Mul_output_0 + bert_embeddings_LayerNorm_bias;
    auto _bert_Shape_1_output_0 = shape(attention_mask);
    auto _bert_Gather_1_output_0 = gather(_bert_Shape_1_output_0, _bert_Constant_1_output_0);
    auto _bert_Shape_2_output_0 = shape(attention_mask);
    auto _bert_Gather_2_output_0 = gather(_bert_Shape_2_output_0, _bert_Constant_2_output_0);
    auto _bert_Unsqueeze_output_0 = unsqueeze<_bert_Constant_3_output_0>(attention_mask);
    auto _bert_Unsqueeze_1_output_0 = unsqueeze<_bert_Constant_4_output_0>(_bert_Unsqueeze_output_0);
    auto _bert_Unsqueeze_2_output_0 = unsqueeze<_bert_Constant_5_output_0>(_bert_Gather_1_output_0);
    auto _bert_Unsqueeze_3_output_0 = unsqueeze<_bert_Constant_7_output_0>(_bert_Gather_output_0);
    auto _bert_Unsqueeze_4_output_0 = unsqueeze<_bert_Constant_8_output_0>(_bert_Gather_2_output_0);
    auto _bert_Concat_output_0 = concat<0>(_bert_Unsqueeze_2_output_0, _bert_Constant_6_output_0, _bert_Unsqueeze_3_output_0, _bert_Unsqueeze_4_output_0);
    auto _bert_Reshape_output_0 = _bert_Concat_output_0.template reshape<_bert_Constant_9_output_0>();
    auto _bert_Shape_3_output_0 = shape(_bert_Reshape_output_0);
    auto _bert_Mul_output_0 = _bert_ConstantOfShape_output_0 * _bert_Constant_10_output_0;
    auto _bert_Equal_output_0 = _bert_Reshape_output_0 == _bert_Mul_output_0;
    auto _bert_Where_output_0 = where(_bert_Equal_output_0, _bert_ConstantOfShape_output_0, _bert_Reshape_output_0);
    auto _bert_Expand_output_0 = _bert_Unsqueeze_1_output_0.template broadcastTo<TYPE(_bert_Where_output_0)>();
    auto _bert_Cast_output_0 = _bert_Expand_output_0.template to<uint8_t>();
    auto _bert_Sub_output_0 = _bert_Constant_11_output_0 - _bert_Cast_output_0;
    auto _bert_Cast_1_output_0 = _bert_Sub_output_0.template to<uint8_t>();
    auto _bert_Cast_2_output_0 = _bert_Cast_1_output_0.template to<uint8_t>();
    auto _bert_Where_1_output_0 = where(_bert_Cast_2_output_0, _bert_Constant_12_output_0, _bert_Sub_output_0);
    auto _bert_encoder_layer_0_attention_self_Shape_output_0 = shape(_bert_embeddings_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_0_attention_self_Gather_output_0 = gather(_bert_encoder_layer_0_attention_self_Shape_output_0, _bert_encoder_layer_0_attention_self_Constant_output_0);
    auto _bert_encoder_layer_0_attention_self_Shape_1_output_0 = shape(_bert_embeddings_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_0_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_0_attention_self_Shape_1_output_0, _bert_encoder_layer_0_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_0_attention_self_query_MatMul_output_0 = matmul<1>(_bert_embeddings_LayerNorm_Add_1_output_0, onnx_MatMul_1899);
    auto _bert_encoder_layer_0_attention_self_query_Add_output_0 = bert_encoder_layer_0_attention_self_query_bias + _bert_encoder_layer_0_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_0_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_0_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_0_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_0_attention_self_Shape_2_output_0, _bert_encoder_layer_0_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_0_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_0_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_0_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_0_attention_self_Shape_3_output_0, _bert_encoder_layer_0_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_0_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_288>(_bert_encoder_layer_0_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_0_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_290>(_bert_encoder_layer_0_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_0_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_0_attention_self_Unsqueeze_output_0, _bert_encoder_layer_0_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_0_attention_self_Constant_4_output_0, _bert_encoder_layer_0_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_0_attention_self_Reshape_output_0 = _bert_encoder_layer_0_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_0_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_0_attention_self_Transpose_output_0 = _bert_encoder_layer_0_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_0_attention_self_key_MatMul_output_0 = matmul<1>(_bert_embeddings_LayerNorm_Add_1_output_0, onnx_MatMul_1902);
    auto _bert_encoder_layer_0_attention_self_key_Add_output_0 = bert_encoder_layer_0_attention_self_key_bias + _bert_encoder_layer_0_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_0_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_0_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_0_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_0_attention_self_Shape_4_output_0, _bert_encoder_layer_0_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_0_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_0_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_0_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_0_attention_self_Shape_5_output_0, _bert_encoder_layer_0_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_0_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_308>(_bert_encoder_layer_0_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_0_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_310>(_bert_encoder_layer_0_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_0_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_0_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_0_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_0_attention_self_Constant_8_output_0, _bert_encoder_layer_0_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_0_attention_self_Reshape_1_output_0 = _bert_encoder_layer_0_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_0_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_0_attention_self_value_MatMul_output_0 = matmul<1>(_bert_embeddings_LayerNorm_Add_1_output_0, onnx_MatMul_1905);
    auto _bert_encoder_layer_0_attention_self_value_Add_output_0 = bert_encoder_layer_0_attention_self_value_bias + _bert_encoder_layer_0_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_0_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_0_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_0_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_0_attention_self_Shape_6_output_0, _bert_encoder_layer_0_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_0_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_0_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_0_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_0_attention_self_Shape_7_output_0, _bert_encoder_layer_0_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_0_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_327>(_bert_encoder_layer_0_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_0_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_329>(_bert_encoder_layer_0_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_0_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_0_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_0_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_0_attention_self_Constant_12_output_0, _bert_encoder_layer_0_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_0_attention_self_Reshape_2_output_0 = _bert_encoder_layer_0_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_0_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_0_attention_self_Transpose_1_output_0 = _bert_encoder_layer_0_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_0_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_0_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_0_attention_self_Slice_output_0 = _bert_encoder_layer_0_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_0_attention_self_Constant_14_output_0,_bert_encoder_layer_0_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_0_attention_self_Cast_output_0 = _bert_encoder_layer_0_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_0_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_0_attention_self_Cast_output_0);
    auto _bert_encoder_layer_0_attention_self_Div_output_0 = _bert_encoder_layer_0_attention_self_Constant_16_output_0 / _bert_encoder_layer_0_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_0_attention_self_Cast_1_output_0 = _bert_encoder_layer_0_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_0_attention_self_Transpose_2_output_0 = _bert_encoder_layer_0_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_0_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_0_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_0_attention_self_Mul_output_0 = _bert_encoder_layer_0_attention_self_Transpose_output_0 * _bert_encoder_layer_0_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_0_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_0_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_0_attention_self_Mul_1_output_0 = _bert_encoder_layer_0_attention_self_Transpose_2_output_0 * _bert_encoder_layer_0_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_0_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_0_attention_self_Mul_output_0, _bert_encoder_layer_0_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_0_attention_self_Add_output_0 = _bert_encoder_layer_0_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_0_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_0_attention_self_Add_output_0);
    auto _bert_encoder_layer_0_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_0_attention_self_Softmax_output_0, _bert_encoder_layer_0_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_0_attention_self_Transpose_3_output_0 = _bert_encoder_layer_0_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_0_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_358>(_bert_encoder_layer_0_attention_self_Gather_output_0);
    auto _bert_encoder_layer_0_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_360>(_bert_encoder_layer_0_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_0_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_0_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_0_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_0_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_0_attention_self_Reshape_3_output_0 = _bert_encoder_layer_0_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_0_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_0_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_0_attention_self_Reshape_3_output_0, onnx_MatMul_1909);
    auto _bert_encoder_layer_0_attention_output_dense_Add_output_0 = bert_encoder_layer_0_attention_output_dense_bias + _bert_encoder_layer_0_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_0_attention_output_Add_output_0 = _bert_encoder_layer_0_attention_output_dense_Add_output_0 + _bert_embeddings_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_0_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_0_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_0_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_0_attention_output_Add_output_0 - _bert_encoder_layer_0_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_0_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_0_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_0_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_0_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_0_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_0_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_0_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_0_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_0_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_0_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_0_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_0_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_0_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_0_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_0_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_0_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_0_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_0_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_0_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_0_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_0_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_1910);
    auto _bert_encoder_layer_0_intermediate_dense_Add_output_0 = bert_encoder_layer_0_intermediate_dense_bias + _bert_encoder_layer_0_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_0_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_0_intermediate_dense_Add_output_0 / _bert_encoder_layer_0_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_0_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_0_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_0_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_0_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_0_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_0_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_0_intermediate_dense_Add_output_0 * _bert_encoder_layer_0_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_0_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_0_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_0_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_0_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_0_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_1911);
    auto _bert_encoder_layer_0_output_dense_Add_output_0 = bert_encoder_layer_0_output_dense_bias + _bert_encoder_layer_0_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_0_output_Add_output_0 = _bert_encoder_layer_0_output_dense_Add_output_0 + _bert_encoder_layer_0_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_0_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_0_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_0_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_0_output_Add_output_0 - _bert_encoder_layer_0_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_0_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_0_output_LayerNorm_Sub_output_0, _bert_encoder_layer_0_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_0_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_0_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_0_output_LayerNorm_Add_output_0 = _bert_encoder_layer_0_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_0_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_0_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_0_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_0_output_LayerNorm_Div_output_0 = _bert_encoder_layer_0_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_0_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_0_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_0_output_LayerNorm_Div_output_0 * bert_encoder_layer_0_output_LayerNorm_weight;
    auto _bert_encoder_layer_0_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_0_output_LayerNorm_Mul_output_0 + bert_encoder_layer_0_output_LayerNorm_bias;
    auto _bert_encoder_layer_1_attention_self_Shape_output_0 = shape(_bert_encoder_layer_0_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_1_attention_self_Gather_output_0 = gather(_bert_encoder_layer_1_attention_self_Shape_output_0, _bert_encoder_layer_1_attention_self_Constant_output_0);
    auto _bert_encoder_layer_1_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_0_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_1_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_1_attention_self_Shape_1_output_0, _bert_encoder_layer_1_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_1_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_0_output_LayerNorm_Add_1_output_0, onnx_MatMul_1912);
    auto _bert_encoder_layer_1_attention_self_query_Add_output_0 = bert_encoder_layer_1_attention_self_query_bias + _bert_encoder_layer_1_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_1_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_1_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_1_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_1_attention_self_Shape_2_output_0, _bert_encoder_layer_1_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_1_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_1_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_1_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_1_attention_self_Shape_3_output_0, _bert_encoder_layer_1_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_1_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_422>(_bert_encoder_layer_1_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_1_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_424>(_bert_encoder_layer_1_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_1_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_1_attention_self_Unsqueeze_output_0, _bert_encoder_layer_1_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_1_attention_self_Constant_4_output_0, _bert_encoder_layer_1_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_1_attention_self_Reshape_output_0 = _bert_encoder_layer_1_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_1_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_1_attention_self_Transpose_output_0 = _bert_encoder_layer_1_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_1_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_0_output_LayerNorm_Add_1_output_0, onnx_MatMul_1915);
    auto _bert_encoder_layer_1_attention_self_key_Add_output_0 = bert_encoder_layer_1_attention_self_key_bias + _bert_encoder_layer_1_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_1_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_1_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_1_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_1_attention_self_Shape_4_output_0, _bert_encoder_layer_1_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_1_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_1_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_1_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_1_attention_self_Shape_5_output_0, _bert_encoder_layer_1_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_1_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_442>(_bert_encoder_layer_1_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_1_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_444>(_bert_encoder_layer_1_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_1_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_1_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_1_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_1_attention_self_Constant_8_output_0, _bert_encoder_layer_1_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_1_attention_self_Reshape_1_output_0 = _bert_encoder_layer_1_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_1_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_1_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_0_output_LayerNorm_Add_1_output_0, onnx_MatMul_1918);
    auto _bert_encoder_layer_1_attention_self_value_Add_output_0 = bert_encoder_layer_1_attention_self_value_bias + _bert_encoder_layer_1_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_1_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_1_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_1_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_1_attention_self_Shape_6_output_0, _bert_encoder_layer_1_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_1_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_1_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_1_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_1_attention_self_Shape_7_output_0, _bert_encoder_layer_1_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_1_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_461>(_bert_encoder_layer_1_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_1_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_463>(_bert_encoder_layer_1_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_1_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_1_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_1_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_1_attention_self_Constant_12_output_0, _bert_encoder_layer_1_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_1_attention_self_Reshape_2_output_0 = _bert_encoder_layer_1_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_1_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_1_attention_self_Transpose_1_output_0 = _bert_encoder_layer_1_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_1_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_1_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_1_attention_self_Slice_output_0 = _bert_encoder_layer_1_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_1_attention_self_Constant_14_output_0,_bert_encoder_layer_1_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_1_attention_self_Cast_output_0 = _bert_encoder_layer_1_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_1_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_1_attention_self_Cast_output_0);
    auto _bert_encoder_layer_1_attention_self_Div_output_0 = _bert_encoder_layer_1_attention_self_Constant_16_output_0 / _bert_encoder_layer_1_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_1_attention_self_Cast_1_output_0 = _bert_encoder_layer_1_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_1_attention_self_Transpose_2_output_0 = _bert_encoder_layer_1_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_1_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_1_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_1_attention_self_Mul_output_0 = _bert_encoder_layer_1_attention_self_Transpose_output_0 * _bert_encoder_layer_1_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_1_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_1_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_1_attention_self_Mul_1_output_0 = _bert_encoder_layer_1_attention_self_Transpose_2_output_0 * _bert_encoder_layer_1_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_1_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_1_attention_self_Mul_output_0, _bert_encoder_layer_1_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_1_attention_self_Add_output_0 = _bert_encoder_layer_1_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_1_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_1_attention_self_Add_output_0);
    auto _bert_encoder_layer_1_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_1_attention_self_Softmax_output_0, _bert_encoder_layer_1_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_1_attention_self_Transpose_3_output_0 = _bert_encoder_layer_1_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_1_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_491>(_bert_encoder_layer_1_attention_self_Gather_output_0);
    auto _bert_encoder_layer_1_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_493>(_bert_encoder_layer_1_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_1_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_1_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_1_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_1_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_1_attention_self_Reshape_3_output_0 = _bert_encoder_layer_1_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_1_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_1_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_1_attention_self_Reshape_3_output_0, onnx_MatMul_1922);
    auto _bert_encoder_layer_1_attention_output_dense_Add_output_0 = bert_encoder_layer_1_attention_output_dense_bias + _bert_encoder_layer_1_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_1_attention_output_Add_output_0 = _bert_encoder_layer_1_attention_output_dense_Add_output_0 + _bert_encoder_layer_0_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_1_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_1_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_1_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_1_attention_output_Add_output_0 - _bert_encoder_layer_1_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_1_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_1_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_1_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_1_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_1_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_1_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_1_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_1_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_1_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_1_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_1_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_1_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_1_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_1_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_1_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_1_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_1_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_1_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_1_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_1_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_1_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_1923);
    auto _bert_encoder_layer_1_intermediate_dense_Add_output_0 = bert_encoder_layer_1_intermediate_dense_bias + _bert_encoder_layer_1_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_1_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_1_intermediate_dense_Add_output_0 / _bert_encoder_layer_1_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_1_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_1_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_1_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_1_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_1_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_1_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_1_intermediate_dense_Add_output_0 * _bert_encoder_layer_1_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_1_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_1_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_1_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_1_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_1_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_1924);
    auto _bert_encoder_layer_1_output_dense_Add_output_0 = bert_encoder_layer_1_output_dense_bias + _bert_encoder_layer_1_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_1_output_Add_output_0 = _bert_encoder_layer_1_output_dense_Add_output_0 + _bert_encoder_layer_1_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_1_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_1_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_1_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_1_output_Add_output_0 - _bert_encoder_layer_1_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_1_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_1_output_LayerNorm_Sub_output_0, _bert_encoder_layer_1_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_1_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_1_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_1_output_LayerNorm_Add_output_0 = _bert_encoder_layer_1_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_1_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_1_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_1_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_1_output_LayerNorm_Div_output_0 = _bert_encoder_layer_1_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_1_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_1_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_1_output_LayerNorm_Div_output_0 * bert_encoder_layer_1_output_LayerNorm_weight;
    auto _bert_encoder_layer_1_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_1_output_LayerNorm_Mul_output_0 + bert_encoder_layer_1_output_LayerNorm_bias;
    auto _bert_encoder_layer_2_attention_self_Shape_output_0 = shape(_bert_encoder_layer_1_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_2_attention_self_Gather_output_0 = gather(_bert_encoder_layer_2_attention_self_Shape_output_0, _bert_encoder_layer_2_attention_self_Constant_output_0);
    auto _bert_encoder_layer_2_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_1_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_2_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_2_attention_self_Shape_1_output_0, _bert_encoder_layer_2_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_2_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_1_output_LayerNorm_Add_1_output_0, onnx_MatMul_1925);
    auto _bert_encoder_layer_2_attention_self_query_Add_output_0 = bert_encoder_layer_2_attention_self_query_bias + _bert_encoder_layer_2_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_2_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_2_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_2_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_2_attention_self_Shape_2_output_0, _bert_encoder_layer_2_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_2_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_2_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_2_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_2_attention_self_Shape_3_output_0, _bert_encoder_layer_2_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_2_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_555>(_bert_encoder_layer_2_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_2_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_557>(_bert_encoder_layer_2_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_2_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_2_attention_self_Unsqueeze_output_0, _bert_encoder_layer_2_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_2_attention_self_Constant_4_output_0, _bert_encoder_layer_2_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_2_attention_self_Reshape_output_0 = _bert_encoder_layer_2_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_2_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_2_attention_self_Transpose_output_0 = _bert_encoder_layer_2_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_2_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_1_output_LayerNorm_Add_1_output_0, onnx_MatMul_1928);
    auto _bert_encoder_layer_2_attention_self_key_Add_output_0 = bert_encoder_layer_2_attention_self_key_bias + _bert_encoder_layer_2_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_2_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_2_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_2_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_2_attention_self_Shape_4_output_0, _bert_encoder_layer_2_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_2_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_2_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_2_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_2_attention_self_Shape_5_output_0, _bert_encoder_layer_2_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_2_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_575>(_bert_encoder_layer_2_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_2_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_577>(_bert_encoder_layer_2_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_2_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_2_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_2_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_2_attention_self_Constant_8_output_0, _bert_encoder_layer_2_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_2_attention_self_Reshape_1_output_0 = _bert_encoder_layer_2_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_2_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_2_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_1_output_LayerNorm_Add_1_output_0, onnx_MatMul_1931);
    auto _bert_encoder_layer_2_attention_self_value_Add_output_0 = bert_encoder_layer_2_attention_self_value_bias + _bert_encoder_layer_2_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_2_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_2_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_2_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_2_attention_self_Shape_6_output_0, _bert_encoder_layer_2_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_2_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_2_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_2_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_2_attention_self_Shape_7_output_0, _bert_encoder_layer_2_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_2_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_594>(_bert_encoder_layer_2_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_2_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_596>(_bert_encoder_layer_2_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_2_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_2_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_2_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_2_attention_self_Constant_12_output_0, _bert_encoder_layer_2_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_2_attention_self_Reshape_2_output_0 = _bert_encoder_layer_2_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_2_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_2_attention_self_Transpose_1_output_0 = _bert_encoder_layer_2_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_2_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_2_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_2_attention_self_Slice_output_0 = _bert_encoder_layer_2_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_2_attention_self_Constant_14_output_0,_bert_encoder_layer_2_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_2_attention_self_Cast_output_0 = _bert_encoder_layer_2_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_2_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_2_attention_self_Cast_output_0);
    auto _bert_encoder_layer_2_attention_self_Div_output_0 = _bert_encoder_layer_2_attention_self_Constant_16_output_0 / _bert_encoder_layer_2_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_2_attention_self_Cast_1_output_0 = _bert_encoder_layer_2_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_2_attention_self_Transpose_2_output_0 = _bert_encoder_layer_2_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_2_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_2_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_2_attention_self_Mul_output_0 = _bert_encoder_layer_2_attention_self_Transpose_output_0 * _bert_encoder_layer_2_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_2_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_2_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_2_attention_self_Mul_1_output_0 = _bert_encoder_layer_2_attention_self_Transpose_2_output_0 * _bert_encoder_layer_2_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_2_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_2_attention_self_Mul_output_0, _bert_encoder_layer_2_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_2_attention_self_Add_output_0 = _bert_encoder_layer_2_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_2_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_2_attention_self_Add_output_0);
    auto _bert_encoder_layer_2_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_2_attention_self_Softmax_output_0, _bert_encoder_layer_2_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_2_attention_self_Transpose_3_output_0 = _bert_encoder_layer_2_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_2_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_624>(_bert_encoder_layer_2_attention_self_Gather_output_0);
    auto _bert_encoder_layer_2_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_626>(_bert_encoder_layer_2_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_2_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_2_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_2_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_2_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_2_attention_self_Reshape_3_output_0 = _bert_encoder_layer_2_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_2_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_2_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_2_attention_self_Reshape_3_output_0, onnx_MatMul_1935);
    auto _bert_encoder_layer_2_attention_output_dense_Add_output_0 = bert_encoder_layer_2_attention_output_dense_bias + _bert_encoder_layer_2_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_2_attention_output_Add_output_0 = _bert_encoder_layer_2_attention_output_dense_Add_output_0 + _bert_encoder_layer_1_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_2_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_2_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_2_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_2_attention_output_Add_output_0 - _bert_encoder_layer_2_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_2_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_2_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_2_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_2_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_2_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_2_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_2_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_2_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_2_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_2_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_2_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_2_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_2_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_2_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_2_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_2_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_2_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_2_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_2_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_2_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_2_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_1936);
    auto _bert_encoder_layer_2_intermediate_dense_Add_output_0 = bert_encoder_layer_2_intermediate_dense_bias + _bert_encoder_layer_2_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_2_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_2_intermediate_dense_Add_output_0 / _bert_encoder_layer_2_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_2_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_2_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_2_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_2_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_2_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_2_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_2_intermediate_dense_Add_output_0 * _bert_encoder_layer_2_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_2_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_2_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_2_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_2_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_2_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_1937);
    auto _bert_encoder_layer_2_output_dense_Add_output_0 = bert_encoder_layer_2_output_dense_bias + _bert_encoder_layer_2_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_2_output_Add_output_0 = _bert_encoder_layer_2_output_dense_Add_output_0 + _bert_encoder_layer_2_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_2_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_2_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_2_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_2_output_Add_output_0 - _bert_encoder_layer_2_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_2_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_2_output_LayerNorm_Sub_output_0, _bert_encoder_layer_2_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_2_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_2_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_2_output_LayerNorm_Add_output_0 = _bert_encoder_layer_2_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_2_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_2_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_2_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_2_output_LayerNorm_Div_output_0 = _bert_encoder_layer_2_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_2_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_2_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_2_output_LayerNorm_Div_output_0 * bert_encoder_layer_2_output_LayerNorm_weight;
    auto _bert_encoder_layer_2_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_2_output_LayerNorm_Mul_output_0 + bert_encoder_layer_2_output_LayerNorm_bias;
    auto _bert_encoder_layer_3_attention_self_Shape_output_0 = shape(_bert_encoder_layer_2_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_3_attention_self_Gather_output_0 = gather(_bert_encoder_layer_3_attention_self_Shape_output_0, _bert_encoder_layer_3_attention_self_Constant_output_0);
    auto _bert_encoder_layer_3_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_2_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_3_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_3_attention_self_Shape_1_output_0, _bert_encoder_layer_3_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_3_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_2_output_LayerNorm_Add_1_output_0, onnx_MatMul_1938);
    auto _bert_encoder_layer_3_attention_self_query_Add_output_0 = bert_encoder_layer_3_attention_self_query_bias + _bert_encoder_layer_3_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_3_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_3_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_3_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_3_attention_self_Shape_2_output_0, _bert_encoder_layer_3_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_3_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_3_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_3_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_3_attention_self_Shape_3_output_0, _bert_encoder_layer_3_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_3_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_688>(_bert_encoder_layer_3_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_3_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_690>(_bert_encoder_layer_3_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_3_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_3_attention_self_Unsqueeze_output_0, _bert_encoder_layer_3_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_3_attention_self_Constant_4_output_0, _bert_encoder_layer_3_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_3_attention_self_Reshape_output_0 = _bert_encoder_layer_3_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_3_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_3_attention_self_Transpose_output_0 = _bert_encoder_layer_3_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_3_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_2_output_LayerNorm_Add_1_output_0, onnx_MatMul_1941);
    auto _bert_encoder_layer_3_attention_self_key_Add_output_0 = bert_encoder_layer_3_attention_self_key_bias + _bert_encoder_layer_3_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_3_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_3_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_3_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_3_attention_self_Shape_4_output_0, _bert_encoder_layer_3_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_3_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_3_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_3_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_3_attention_self_Shape_5_output_0, _bert_encoder_layer_3_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_3_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_708>(_bert_encoder_layer_3_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_3_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_710>(_bert_encoder_layer_3_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_3_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_3_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_3_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_3_attention_self_Constant_8_output_0, _bert_encoder_layer_3_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_3_attention_self_Reshape_1_output_0 = _bert_encoder_layer_3_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_3_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_3_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_2_output_LayerNorm_Add_1_output_0, onnx_MatMul_1944);
    auto _bert_encoder_layer_3_attention_self_value_Add_output_0 = bert_encoder_layer_3_attention_self_value_bias + _bert_encoder_layer_3_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_3_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_3_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_3_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_3_attention_self_Shape_6_output_0, _bert_encoder_layer_3_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_3_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_3_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_3_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_3_attention_self_Shape_7_output_0, _bert_encoder_layer_3_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_3_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_727>(_bert_encoder_layer_3_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_3_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_729>(_bert_encoder_layer_3_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_3_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_3_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_3_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_3_attention_self_Constant_12_output_0, _bert_encoder_layer_3_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_3_attention_self_Reshape_2_output_0 = _bert_encoder_layer_3_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_3_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_3_attention_self_Transpose_1_output_0 = _bert_encoder_layer_3_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_3_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_3_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_3_attention_self_Slice_output_0 = _bert_encoder_layer_3_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_3_attention_self_Constant_14_output_0,_bert_encoder_layer_3_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_3_attention_self_Cast_output_0 = _bert_encoder_layer_3_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_3_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_3_attention_self_Cast_output_0);
    auto _bert_encoder_layer_3_attention_self_Div_output_0 = _bert_encoder_layer_3_attention_self_Constant_16_output_0 / _bert_encoder_layer_3_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_3_attention_self_Cast_1_output_0 = _bert_encoder_layer_3_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_3_attention_self_Transpose_2_output_0 = _bert_encoder_layer_3_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_3_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_3_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_3_attention_self_Mul_output_0 = _bert_encoder_layer_3_attention_self_Transpose_output_0 * _bert_encoder_layer_3_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_3_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_3_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_3_attention_self_Mul_1_output_0 = _bert_encoder_layer_3_attention_self_Transpose_2_output_0 * _bert_encoder_layer_3_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_3_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_3_attention_self_Mul_output_0, _bert_encoder_layer_3_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_3_attention_self_Add_output_0 = _bert_encoder_layer_3_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_3_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_3_attention_self_Add_output_0);
    auto _bert_encoder_layer_3_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_3_attention_self_Softmax_output_0, _bert_encoder_layer_3_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_3_attention_self_Transpose_3_output_0 = _bert_encoder_layer_3_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_3_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_757>(_bert_encoder_layer_3_attention_self_Gather_output_0);
    auto _bert_encoder_layer_3_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_759>(_bert_encoder_layer_3_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_3_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_3_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_3_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_3_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_3_attention_self_Reshape_3_output_0 = _bert_encoder_layer_3_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_3_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_3_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_3_attention_self_Reshape_3_output_0, onnx_MatMul_1948);
    auto _bert_encoder_layer_3_attention_output_dense_Add_output_0 = bert_encoder_layer_3_attention_output_dense_bias + _bert_encoder_layer_3_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_3_attention_output_Add_output_0 = _bert_encoder_layer_3_attention_output_dense_Add_output_0 + _bert_encoder_layer_2_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_3_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_3_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_3_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_3_attention_output_Add_output_0 - _bert_encoder_layer_3_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_3_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_3_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_3_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_3_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_3_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_3_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_3_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_3_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_3_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_3_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_3_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_3_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_3_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_3_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_3_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_3_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_3_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_3_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_3_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_3_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_3_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_1949);
    auto _bert_encoder_layer_3_intermediate_dense_Add_output_0 = bert_encoder_layer_3_intermediate_dense_bias + _bert_encoder_layer_3_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_3_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_3_intermediate_dense_Add_output_0 / _bert_encoder_layer_3_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_3_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_3_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_3_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_3_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_3_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_3_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_3_intermediate_dense_Add_output_0 * _bert_encoder_layer_3_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_3_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_3_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_3_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_3_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_3_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_1950);
    auto _bert_encoder_layer_3_output_dense_Add_output_0 = bert_encoder_layer_3_output_dense_bias + _bert_encoder_layer_3_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_3_output_Add_output_0 = _bert_encoder_layer_3_output_dense_Add_output_0 + _bert_encoder_layer_3_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_3_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_3_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_3_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_3_output_Add_output_0 - _bert_encoder_layer_3_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_3_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_3_output_LayerNorm_Sub_output_0, _bert_encoder_layer_3_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_3_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_3_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_3_output_LayerNorm_Add_output_0 = _bert_encoder_layer_3_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_3_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_3_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_3_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_3_output_LayerNorm_Div_output_0 = _bert_encoder_layer_3_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_3_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_3_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_3_output_LayerNorm_Div_output_0 * bert_encoder_layer_3_output_LayerNorm_weight;
    auto _bert_encoder_layer_3_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_3_output_LayerNorm_Mul_output_0 + bert_encoder_layer_3_output_LayerNorm_bias;
    auto _bert_encoder_layer_4_attention_self_Shape_output_0 = shape(_bert_encoder_layer_3_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_4_attention_self_Gather_output_0 = gather(_bert_encoder_layer_4_attention_self_Shape_output_0, _bert_encoder_layer_4_attention_self_Constant_output_0);
    auto _bert_encoder_layer_4_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_3_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_4_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_4_attention_self_Shape_1_output_0, _bert_encoder_layer_4_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_4_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_3_output_LayerNorm_Add_1_output_0, onnx_MatMul_1951);
    auto _bert_encoder_layer_4_attention_self_query_Add_output_0 = bert_encoder_layer_4_attention_self_query_bias + _bert_encoder_layer_4_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_4_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_4_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_4_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_4_attention_self_Shape_2_output_0, _bert_encoder_layer_4_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_4_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_4_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_4_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_4_attention_self_Shape_3_output_0, _bert_encoder_layer_4_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_4_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_821>(_bert_encoder_layer_4_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_4_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_823>(_bert_encoder_layer_4_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_4_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_4_attention_self_Unsqueeze_output_0, _bert_encoder_layer_4_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_4_attention_self_Constant_4_output_0, _bert_encoder_layer_4_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_4_attention_self_Reshape_output_0 = _bert_encoder_layer_4_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_4_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_4_attention_self_Transpose_output_0 = _bert_encoder_layer_4_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_4_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_3_output_LayerNorm_Add_1_output_0, onnx_MatMul_1954);
    auto _bert_encoder_layer_4_attention_self_key_Add_output_0 = bert_encoder_layer_4_attention_self_key_bias + _bert_encoder_layer_4_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_4_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_4_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_4_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_4_attention_self_Shape_4_output_0, _bert_encoder_layer_4_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_4_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_4_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_4_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_4_attention_self_Shape_5_output_0, _bert_encoder_layer_4_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_4_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_841>(_bert_encoder_layer_4_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_4_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_843>(_bert_encoder_layer_4_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_4_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_4_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_4_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_4_attention_self_Constant_8_output_0, _bert_encoder_layer_4_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_4_attention_self_Reshape_1_output_0 = _bert_encoder_layer_4_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_4_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_4_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_3_output_LayerNorm_Add_1_output_0, onnx_MatMul_1957);
    auto _bert_encoder_layer_4_attention_self_value_Add_output_0 = bert_encoder_layer_4_attention_self_value_bias + _bert_encoder_layer_4_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_4_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_4_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_4_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_4_attention_self_Shape_6_output_0, _bert_encoder_layer_4_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_4_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_4_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_4_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_4_attention_self_Shape_7_output_0, _bert_encoder_layer_4_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_4_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_860>(_bert_encoder_layer_4_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_4_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_862>(_bert_encoder_layer_4_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_4_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_4_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_4_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_4_attention_self_Constant_12_output_0, _bert_encoder_layer_4_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_4_attention_self_Reshape_2_output_0 = _bert_encoder_layer_4_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_4_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_4_attention_self_Transpose_1_output_0 = _bert_encoder_layer_4_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_4_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_4_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_4_attention_self_Slice_output_0 = _bert_encoder_layer_4_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_4_attention_self_Constant_14_output_0,_bert_encoder_layer_4_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_4_attention_self_Cast_output_0 = _bert_encoder_layer_4_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_4_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_4_attention_self_Cast_output_0);
    auto _bert_encoder_layer_4_attention_self_Div_output_0 = _bert_encoder_layer_4_attention_self_Constant_16_output_0 / _bert_encoder_layer_4_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_4_attention_self_Cast_1_output_0 = _bert_encoder_layer_4_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_4_attention_self_Transpose_2_output_0 = _bert_encoder_layer_4_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_4_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_4_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_4_attention_self_Mul_output_0 = _bert_encoder_layer_4_attention_self_Transpose_output_0 * _bert_encoder_layer_4_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_4_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_4_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_4_attention_self_Mul_1_output_0 = _bert_encoder_layer_4_attention_self_Transpose_2_output_0 * _bert_encoder_layer_4_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_4_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_4_attention_self_Mul_output_0, _bert_encoder_layer_4_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_4_attention_self_Add_output_0 = _bert_encoder_layer_4_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_4_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_4_attention_self_Add_output_0);
    auto _bert_encoder_layer_4_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_4_attention_self_Softmax_output_0, _bert_encoder_layer_4_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_4_attention_self_Transpose_3_output_0 = _bert_encoder_layer_4_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_4_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_890>(_bert_encoder_layer_4_attention_self_Gather_output_0);
    auto _bert_encoder_layer_4_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_892>(_bert_encoder_layer_4_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_4_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_4_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_4_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_4_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_4_attention_self_Reshape_3_output_0 = _bert_encoder_layer_4_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_4_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_4_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_4_attention_self_Reshape_3_output_0, onnx_MatMul_1961);
    auto _bert_encoder_layer_4_attention_output_dense_Add_output_0 = bert_encoder_layer_4_attention_output_dense_bias + _bert_encoder_layer_4_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_4_attention_output_Add_output_0 = _bert_encoder_layer_4_attention_output_dense_Add_output_0 + _bert_encoder_layer_3_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_4_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_4_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_4_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_4_attention_output_Add_output_0 - _bert_encoder_layer_4_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_4_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_4_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_4_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_4_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_4_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_4_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_4_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_4_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_4_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_4_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_4_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_4_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_4_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_4_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_4_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_4_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_4_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_4_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_4_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_4_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_4_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_1962);
    auto _bert_encoder_layer_4_intermediate_dense_Add_output_0 = bert_encoder_layer_4_intermediate_dense_bias + _bert_encoder_layer_4_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_4_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_4_intermediate_dense_Add_output_0 / _bert_encoder_layer_4_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_4_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_4_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_4_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_4_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_4_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_4_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_4_intermediate_dense_Add_output_0 * _bert_encoder_layer_4_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_4_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_4_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_4_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_4_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_4_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_1963);
    auto _bert_encoder_layer_4_output_dense_Add_output_0 = bert_encoder_layer_4_output_dense_bias + _bert_encoder_layer_4_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_4_output_Add_output_0 = _bert_encoder_layer_4_output_dense_Add_output_0 + _bert_encoder_layer_4_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_4_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_4_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_4_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_4_output_Add_output_0 - _bert_encoder_layer_4_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_4_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_4_output_LayerNorm_Sub_output_0, _bert_encoder_layer_4_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_4_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_4_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_4_output_LayerNorm_Add_output_0 = _bert_encoder_layer_4_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_4_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_4_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_4_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_4_output_LayerNorm_Div_output_0 = _bert_encoder_layer_4_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_4_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_4_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_4_output_LayerNorm_Div_output_0 * bert_encoder_layer_4_output_LayerNorm_weight;
    auto _bert_encoder_layer_4_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_4_output_LayerNorm_Mul_output_0 + bert_encoder_layer_4_output_LayerNorm_bias;
    auto _bert_encoder_layer_5_attention_self_Shape_output_0 = shape(_bert_encoder_layer_4_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_5_attention_self_Gather_output_0 = gather(_bert_encoder_layer_5_attention_self_Shape_output_0, _bert_encoder_layer_5_attention_self_Constant_output_0);
    auto _bert_encoder_layer_5_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_4_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_5_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_5_attention_self_Shape_1_output_0, _bert_encoder_layer_5_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_5_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_4_output_LayerNorm_Add_1_output_0, onnx_MatMul_1964);
    auto _bert_encoder_layer_5_attention_self_query_Add_output_0 = bert_encoder_layer_5_attention_self_query_bias + _bert_encoder_layer_5_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_5_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_5_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_5_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_5_attention_self_Shape_2_output_0, _bert_encoder_layer_5_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_5_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_5_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_5_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_5_attention_self_Shape_3_output_0, _bert_encoder_layer_5_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_5_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_954>(_bert_encoder_layer_5_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_5_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_956>(_bert_encoder_layer_5_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_5_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_5_attention_self_Unsqueeze_output_0, _bert_encoder_layer_5_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_5_attention_self_Constant_4_output_0, _bert_encoder_layer_5_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_5_attention_self_Reshape_output_0 = _bert_encoder_layer_5_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_5_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_5_attention_self_Transpose_output_0 = _bert_encoder_layer_5_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_5_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_4_output_LayerNorm_Add_1_output_0, onnx_MatMul_1967);
    auto _bert_encoder_layer_5_attention_self_key_Add_output_0 = bert_encoder_layer_5_attention_self_key_bias + _bert_encoder_layer_5_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_5_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_5_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_5_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_5_attention_self_Shape_4_output_0, _bert_encoder_layer_5_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_5_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_5_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_5_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_5_attention_self_Shape_5_output_0, _bert_encoder_layer_5_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_5_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_974>(_bert_encoder_layer_5_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_5_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_976>(_bert_encoder_layer_5_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_5_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_5_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_5_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_5_attention_self_Constant_8_output_0, _bert_encoder_layer_5_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_5_attention_self_Reshape_1_output_0 = _bert_encoder_layer_5_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_5_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_5_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_4_output_LayerNorm_Add_1_output_0, onnx_MatMul_1970);
    auto _bert_encoder_layer_5_attention_self_value_Add_output_0 = bert_encoder_layer_5_attention_self_value_bias + _bert_encoder_layer_5_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_5_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_5_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_5_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_5_attention_self_Shape_6_output_0, _bert_encoder_layer_5_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_5_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_5_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_5_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_5_attention_self_Shape_7_output_0, _bert_encoder_layer_5_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_5_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_993>(_bert_encoder_layer_5_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_5_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_995>(_bert_encoder_layer_5_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_5_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_5_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_5_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_5_attention_self_Constant_12_output_0, _bert_encoder_layer_5_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_5_attention_self_Reshape_2_output_0 = _bert_encoder_layer_5_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_5_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_5_attention_self_Transpose_1_output_0 = _bert_encoder_layer_5_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_5_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_5_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_5_attention_self_Slice_output_0 = _bert_encoder_layer_5_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_5_attention_self_Constant_14_output_0,_bert_encoder_layer_5_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_5_attention_self_Cast_output_0 = _bert_encoder_layer_5_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_5_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_5_attention_self_Cast_output_0);
    auto _bert_encoder_layer_5_attention_self_Div_output_0 = _bert_encoder_layer_5_attention_self_Constant_16_output_0 / _bert_encoder_layer_5_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_5_attention_self_Cast_1_output_0 = _bert_encoder_layer_5_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_5_attention_self_Transpose_2_output_0 = _bert_encoder_layer_5_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_5_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_5_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_5_attention_self_Mul_output_0 = _bert_encoder_layer_5_attention_self_Transpose_output_0 * _bert_encoder_layer_5_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_5_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_5_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_5_attention_self_Mul_1_output_0 = _bert_encoder_layer_5_attention_self_Transpose_2_output_0 * _bert_encoder_layer_5_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_5_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_5_attention_self_Mul_output_0, _bert_encoder_layer_5_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_5_attention_self_Add_output_0 = _bert_encoder_layer_5_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_5_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_5_attention_self_Add_output_0);
    auto _bert_encoder_layer_5_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_5_attention_self_Softmax_output_0, _bert_encoder_layer_5_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_5_attention_self_Transpose_3_output_0 = _bert_encoder_layer_5_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_5_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_1023>(_bert_encoder_layer_5_attention_self_Gather_output_0);
    auto _bert_encoder_layer_5_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_1025>(_bert_encoder_layer_5_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_5_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_5_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_5_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_5_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_5_attention_self_Reshape_3_output_0 = _bert_encoder_layer_5_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_5_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_5_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_5_attention_self_Reshape_3_output_0, onnx_MatMul_1974);
    auto _bert_encoder_layer_5_attention_output_dense_Add_output_0 = bert_encoder_layer_5_attention_output_dense_bias + _bert_encoder_layer_5_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_5_attention_output_Add_output_0 = _bert_encoder_layer_5_attention_output_dense_Add_output_0 + _bert_encoder_layer_4_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_5_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_5_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_5_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_5_attention_output_Add_output_0 - _bert_encoder_layer_5_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_5_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_5_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_5_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_5_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_5_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_5_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_5_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_5_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_5_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_5_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_5_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_5_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_5_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_5_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_5_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_5_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_5_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_5_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_5_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_5_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_5_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_1975);
    auto _bert_encoder_layer_5_intermediate_dense_Add_output_0 = bert_encoder_layer_5_intermediate_dense_bias + _bert_encoder_layer_5_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_5_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_5_intermediate_dense_Add_output_0 / _bert_encoder_layer_5_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_5_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_5_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_5_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_5_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_5_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_5_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_5_intermediate_dense_Add_output_0 * _bert_encoder_layer_5_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_5_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_5_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_5_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_5_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_5_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_1976);
    auto _bert_encoder_layer_5_output_dense_Add_output_0 = bert_encoder_layer_5_output_dense_bias + _bert_encoder_layer_5_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_5_output_Add_output_0 = _bert_encoder_layer_5_output_dense_Add_output_0 + _bert_encoder_layer_5_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_5_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_5_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_5_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_5_output_Add_output_0 - _bert_encoder_layer_5_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_5_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_5_output_LayerNorm_Sub_output_0, _bert_encoder_layer_5_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_5_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_5_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_5_output_LayerNorm_Add_output_0 = _bert_encoder_layer_5_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_5_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_5_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_5_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_5_output_LayerNorm_Div_output_0 = _bert_encoder_layer_5_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_5_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_5_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_5_output_LayerNorm_Div_output_0 * bert_encoder_layer_5_output_LayerNorm_weight;
    auto _bert_encoder_layer_5_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_5_output_LayerNorm_Mul_output_0 + bert_encoder_layer_5_output_LayerNorm_bias;
    auto _bert_encoder_layer_6_attention_self_Shape_output_0 = shape(_bert_encoder_layer_5_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_6_attention_self_Gather_output_0 = gather(_bert_encoder_layer_6_attention_self_Shape_output_0, _bert_encoder_layer_6_attention_self_Constant_output_0);
    auto _bert_encoder_layer_6_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_5_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_6_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_6_attention_self_Shape_1_output_0, _bert_encoder_layer_6_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_6_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_5_output_LayerNorm_Add_1_output_0, onnx_MatMul_1977);
    auto _bert_encoder_layer_6_attention_self_query_Add_output_0 = bert_encoder_layer_6_attention_self_query_bias + _bert_encoder_layer_6_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_6_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_6_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_6_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_6_attention_self_Shape_2_output_0, _bert_encoder_layer_6_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_6_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_6_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_6_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_6_attention_self_Shape_3_output_0, _bert_encoder_layer_6_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_6_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_1087>(_bert_encoder_layer_6_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_6_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_1089>(_bert_encoder_layer_6_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_6_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_6_attention_self_Unsqueeze_output_0, _bert_encoder_layer_6_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_6_attention_self_Constant_4_output_0, _bert_encoder_layer_6_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_6_attention_self_Reshape_output_0 = _bert_encoder_layer_6_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_6_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_6_attention_self_Transpose_output_0 = _bert_encoder_layer_6_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_6_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_5_output_LayerNorm_Add_1_output_0, onnx_MatMul_1980);
    auto _bert_encoder_layer_6_attention_self_key_Add_output_0 = bert_encoder_layer_6_attention_self_key_bias + _bert_encoder_layer_6_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_6_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_6_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_6_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_6_attention_self_Shape_4_output_0, _bert_encoder_layer_6_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_6_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_6_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_6_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_6_attention_self_Shape_5_output_0, _bert_encoder_layer_6_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_6_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_1107>(_bert_encoder_layer_6_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_6_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_1109>(_bert_encoder_layer_6_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_6_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_6_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_6_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_6_attention_self_Constant_8_output_0, _bert_encoder_layer_6_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_6_attention_self_Reshape_1_output_0 = _bert_encoder_layer_6_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_6_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_6_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_5_output_LayerNorm_Add_1_output_0, onnx_MatMul_1983);
    auto _bert_encoder_layer_6_attention_self_value_Add_output_0 = bert_encoder_layer_6_attention_self_value_bias + _bert_encoder_layer_6_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_6_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_6_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_6_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_6_attention_self_Shape_6_output_0, _bert_encoder_layer_6_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_6_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_6_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_6_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_6_attention_self_Shape_7_output_0, _bert_encoder_layer_6_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_6_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_1126>(_bert_encoder_layer_6_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_6_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_1128>(_bert_encoder_layer_6_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_6_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_6_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_6_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_6_attention_self_Constant_12_output_0, _bert_encoder_layer_6_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_6_attention_self_Reshape_2_output_0 = _bert_encoder_layer_6_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_6_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_6_attention_self_Transpose_1_output_0 = _bert_encoder_layer_6_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_6_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_6_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_6_attention_self_Slice_output_0 = _bert_encoder_layer_6_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_6_attention_self_Constant_14_output_0,_bert_encoder_layer_6_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_6_attention_self_Cast_output_0 = _bert_encoder_layer_6_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_6_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_6_attention_self_Cast_output_0);
    auto _bert_encoder_layer_6_attention_self_Div_output_0 = _bert_encoder_layer_6_attention_self_Constant_16_output_0 / _bert_encoder_layer_6_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_6_attention_self_Cast_1_output_0 = _bert_encoder_layer_6_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_6_attention_self_Transpose_2_output_0 = _bert_encoder_layer_6_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_6_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_6_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_6_attention_self_Mul_output_0 = _bert_encoder_layer_6_attention_self_Transpose_output_0 * _bert_encoder_layer_6_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_6_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_6_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_6_attention_self_Mul_1_output_0 = _bert_encoder_layer_6_attention_self_Transpose_2_output_0 * _bert_encoder_layer_6_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_6_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_6_attention_self_Mul_output_0, _bert_encoder_layer_6_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_6_attention_self_Add_output_0 = _bert_encoder_layer_6_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_6_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_6_attention_self_Add_output_0);
    auto _bert_encoder_layer_6_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_6_attention_self_Softmax_output_0, _bert_encoder_layer_6_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_6_attention_self_Transpose_3_output_0 = _bert_encoder_layer_6_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_6_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_1156>(_bert_encoder_layer_6_attention_self_Gather_output_0);
    auto _bert_encoder_layer_6_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_1158>(_bert_encoder_layer_6_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_6_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_6_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_6_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_6_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_6_attention_self_Reshape_3_output_0 = _bert_encoder_layer_6_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_6_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_6_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_6_attention_self_Reshape_3_output_0, onnx_MatMul_1987);
    auto _bert_encoder_layer_6_attention_output_dense_Add_output_0 = bert_encoder_layer_6_attention_output_dense_bias + _bert_encoder_layer_6_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_6_attention_output_Add_output_0 = _bert_encoder_layer_6_attention_output_dense_Add_output_0 + _bert_encoder_layer_5_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_6_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_6_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_6_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_6_attention_output_Add_output_0 - _bert_encoder_layer_6_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_6_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_6_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_6_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_6_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_6_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_6_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_6_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_6_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_6_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_6_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_6_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_6_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_6_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_6_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_6_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_6_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_6_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_6_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_6_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_6_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_6_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_1988);
    auto _bert_encoder_layer_6_intermediate_dense_Add_output_0 = bert_encoder_layer_6_intermediate_dense_bias + _bert_encoder_layer_6_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_6_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_6_intermediate_dense_Add_output_0 / _bert_encoder_layer_6_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_6_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_6_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_6_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_6_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_6_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_6_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_6_intermediate_dense_Add_output_0 * _bert_encoder_layer_6_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_6_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_6_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_6_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_6_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_6_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_1989);
    auto _bert_encoder_layer_6_output_dense_Add_output_0 = bert_encoder_layer_6_output_dense_bias + _bert_encoder_layer_6_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_6_output_Add_output_0 = _bert_encoder_layer_6_output_dense_Add_output_0 + _bert_encoder_layer_6_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_6_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_6_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_6_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_6_output_Add_output_0 - _bert_encoder_layer_6_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_6_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_6_output_LayerNorm_Sub_output_0, _bert_encoder_layer_6_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_6_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_6_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_6_output_LayerNorm_Add_output_0 = _bert_encoder_layer_6_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_6_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_6_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_6_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_6_output_LayerNorm_Div_output_0 = _bert_encoder_layer_6_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_6_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_6_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_6_output_LayerNorm_Div_output_0 * bert_encoder_layer_6_output_LayerNorm_weight;
    auto _bert_encoder_layer_6_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_6_output_LayerNorm_Mul_output_0 + bert_encoder_layer_6_output_LayerNorm_bias;
    auto _bert_encoder_layer_7_attention_self_Shape_output_0 = shape(_bert_encoder_layer_6_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_7_attention_self_Gather_output_0 = gather(_bert_encoder_layer_7_attention_self_Shape_output_0, _bert_encoder_layer_7_attention_self_Constant_output_0);
    auto _bert_encoder_layer_7_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_6_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_7_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_7_attention_self_Shape_1_output_0, _bert_encoder_layer_7_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_7_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_6_output_LayerNorm_Add_1_output_0, onnx_MatMul_1990);
    auto _bert_encoder_layer_7_attention_self_query_Add_output_0 = bert_encoder_layer_7_attention_self_query_bias + _bert_encoder_layer_7_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_7_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_7_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_7_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_7_attention_self_Shape_2_output_0, _bert_encoder_layer_7_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_7_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_7_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_7_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_7_attention_self_Shape_3_output_0, _bert_encoder_layer_7_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_7_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_1220>(_bert_encoder_layer_7_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_7_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_1222>(_bert_encoder_layer_7_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_7_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_7_attention_self_Unsqueeze_output_0, _bert_encoder_layer_7_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_7_attention_self_Constant_4_output_0, _bert_encoder_layer_7_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_7_attention_self_Reshape_output_0 = _bert_encoder_layer_7_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_7_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_7_attention_self_Transpose_output_0 = _bert_encoder_layer_7_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_7_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_6_output_LayerNorm_Add_1_output_0, onnx_MatMul_1993);
    auto _bert_encoder_layer_7_attention_self_key_Add_output_0 = bert_encoder_layer_7_attention_self_key_bias + _bert_encoder_layer_7_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_7_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_7_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_7_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_7_attention_self_Shape_4_output_0, _bert_encoder_layer_7_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_7_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_7_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_7_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_7_attention_self_Shape_5_output_0, _bert_encoder_layer_7_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_7_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_1240>(_bert_encoder_layer_7_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_7_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_1242>(_bert_encoder_layer_7_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_7_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_7_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_7_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_7_attention_self_Constant_8_output_0, _bert_encoder_layer_7_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_7_attention_self_Reshape_1_output_0 = _bert_encoder_layer_7_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_7_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_7_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_6_output_LayerNorm_Add_1_output_0, onnx_MatMul_1996);
    auto _bert_encoder_layer_7_attention_self_value_Add_output_0 = bert_encoder_layer_7_attention_self_value_bias + _bert_encoder_layer_7_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_7_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_7_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_7_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_7_attention_self_Shape_6_output_0, _bert_encoder_layer_7_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_7_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_7_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_7_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_7_attention_self_Shape_7_output_0, _bert_encoder_layer_7_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_7_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_1259>(_bert_encoder_layer_7_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_7_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_1261>(_bert_encoder_layer_7_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_7_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_7_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_7_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_7_attention_self_Constant_12_output_0, _bert_encoder_layer_7_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_7_attention_self_Reshape_2_output_0 = _bert_encoder_layer_7_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_7_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_7_attention_self_Transpose_1_output_0 = _bert_encoder_layer_7_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_7_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_7_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_7_attention_self_Slice_output_0 = _bert_encoder_layer_7_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_7_attention_self_Constant_14_output_0,_bert_encoder_layer_7_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_7_attention_self_Cast_output_0 = _bert_encoder_layer_7_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_7_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_7_attention_self_Cast_output_0);
    auto _bert_encoder_layer_7_attention_self_Div_output_0 = _bert_encoder_layer_7_attention_self_Constant_16_output_0 / _bert_encoder_layer_7_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_7_attention_self_Cast_1_output_0 = _bert_encoder_layer_7_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_7_attention_self_Transpose_2_output_0 = _bert_encoder_layer_7_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_7_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_7_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_7_attention_self_Mul_output_0 = _bert_encoder_layer_7_attention_self_Transpose_output_0 * _bert_encoder_layer_7_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_7_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_7_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_7_attention_self_Mul_1_output_0 = _bert_encoder_layer_7_attention_self_Transpose_2_output_0 * _bert_encoder_layer_7_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_7_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_7_attention_self_Mul_output_0, _bert_encoder_layer_7_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_7_attention_self_Add_output_0 = _bert_encoder_layer_7_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_7_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_7_attention_self_Add_output_0);
    auto _bert_encoder_layer_7_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_7_attention_self_Softmax_output_0, _bert_encoder_layer_7_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_7_attention_self_Transpose_3_output_0 = _bert_encoder_layer_7_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_7_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_1289>(_bert_encoder_layer_7_attention_self_Gather_output_0);
    auto _bert_encoder_layer_7_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_1291>(_bert_encoder_layer_7_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_7_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_7_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_7_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_7_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_7_attention_self_Reshape_3_output_0 = _bert_encoder_layer_7_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_7_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_7_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_7_attention_self_Reshape_3_output_0, onnx_MatMul_2000);
    auto _bert_encoder_layer_7_attention_output_dense_Add_output_0 = bert_encoder_layer_7_attention_output_dense_bias + _bert_encoder_layer_7_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_7_attention_output_Add_output_0 = _bert_encoder_layer_7_attention_output_dense_Add_output_0 + _bert_encoder_layer_6_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_7_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_7_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_7_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_7_attention_output_Add_output_0 - _bert_encoder_layer_7_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_7_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_7_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_7_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_7_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_7_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_7_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_7_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_7_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_7_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_7_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_7_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_7_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_7_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_7_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_7_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_7_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_7_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_7_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_7_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_7_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_7_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_2001);
    auto _bert_encoder_layer_7_intermediate_dense_Add_output_0 = bert_encoder_layer_7_intermediate_dense_bias + _bert_encoder_layer_7_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_7_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_7_intermediate_dense_Add_output_0 / _bert_encoder_layer_7_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_7_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_7_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_7_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_7_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_7_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_7_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_7_intermediate_dense_Add_output_0 * _bert_encoder_layer_7_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_7_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_7_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_7_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_7_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_7_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_2002);
    auto _bert_encoder_layer_7_output_dense_Add_output_0 = bert_encoder_layer_7_output_dense_bias + _bert_encoder_layer_7_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_7_output_Add_output_0 = _bert_encoder_layer_7_output_dense_Add_output_0 + _bert_encoder_layer_7_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_7_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_7_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_7_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_7_output_Add_output_0 - _bert_encoder_layer_7_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_7_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_7_output_LayerNorm_Sub_output_0, _bert_encoder_layer_7_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_7_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_7_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_7_output_LayerNorm_Add_output_0 = _bert_encoder_layer_7_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_7_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_7_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_7_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_7_output_LayerNorm_Div_output_0 = _bert_encoder_layer_7_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_7_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_7_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_7_output_LayerNorm_Div_output_0 * bert_encoder_layer_7_output_LayerNorm_weight;
    auto _bert_encoder_layer_7_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_7_output_LayerNorm_Mul_output_0 + bert_encoder_layer_7_output_LayerNorm_bias;
    auto _bert_encoder_layer_8_attention_self_Shape_output_0 = shape(_bert_encoder_layer_7_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_8_attention_self_Gather_output_0 = gather(_bert_encoder_layer_8_attention_self_Shape_output_0, _bert_encoder_layer_8_attention_self_Constant_output_0);
    auto _bert_encoder_layer_8_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_7_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_8_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_8_attention_self_Shape_1_output_0, _bert_encoder_layer_8_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_8_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_7_output_LayerNorm_Add_1_output_0, onnx_MatMul_2003);
    auto _bert_encoder_layer_8_attention_self_query_Add_output_0 = bert_encoder_layer_8_attention_self_query_bias + _bert_encoder_layer_8_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_8_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_8_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_8_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_8_attention_self_Shape_2_output_0, _bert_encoder_layer_8_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_8_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_8_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_8_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_8_attention_self_Shape_3_output_0, _bert_encoder_layer_8_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_8_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_1353>(_bert_encoder_layer_8_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_8_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_1355>(_bert_encoder_layer_8_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_8_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_8_attention_self_Unsqueeze_output_0, _bert_encoder_layer_8_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_8_attention_self_Constant_4_output_0, _bert_encoder_layer_8_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_8_attention_self_Reshape_output_0 = _bert_encoder_layer_8_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_8_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_8_attention_self_Transpose_output_0 = _bert_encoder_layer_8_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_8_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_7_output_LayerNorm_Add_1_output_0, onnx_MatMul_2006);
    auto _bert_encoder_layer_8_attention_self_key_Add_output_0 = bert_encoder_layer_8_attention_self_key_bias + _bert_encoder_layer_8_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_8_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_8_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_8_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_8_attention_self_Shape_4_output_0, _bert_encoder_layer_8_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_8_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_8_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_8_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_8_attention_self_Shape_5_output_0, _bert_encoder_layer_8_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_8_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_1373>(_bert_encoder_layer_8_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_8_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_1375>(_bert_encoder_layer_8_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_8_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_8_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_8_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_8_attention_self_Constant_8_output_0, _bert_encoder_layer_8_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_8_attention_self_Reshape_1_output_0 = _bert_encoder_layer_8_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_8_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_8_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_7_output_LayerNorm_Add_1_output_0, onnx_MatMul_2009);
    auto _bert_encoder_layer_8_attention_self_value_Add_output_0 = bert_encoder_layer_8_attention_self_value_bias + _bert_encoder_layer_8_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_8_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_8_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_8_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_8_attention_self_Shape_6_output_0, _bert_encoder_layer_8_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_8_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_8_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_8_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_8_attention_self_Shape_7_output_0, _bert_encoder_layer_8_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_8_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_1392>(_bert_encoder_layer_8_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_8_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_1394>(_bert_encoder_layer_8_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_8_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_8_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_8_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_8_attention_self_Constant_12_output_0, _bert_encoder_layer_8_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_8_attention_self_Reshape_2_output_0 = _bert_encoder_layer_8_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_8_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_8_attention_self_Transpose_1_output_0 = _bert_encoder_layer_8_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_8_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_8_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_8_attention_self_Slice_output_0 = _bert_encoder_layer_8_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_8_attention_self_Constant_14_output_0,_bert_encoder_layer_8_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_8_attention_self_Cast_output_0 = _bert_encoder_layer_8_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_8_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_8_attention_self_Cast_output_0);
    auto _bert_encoder_layer_8_attention_self_Div_output_0 = _bert_encoder_layer_8_attention_self_Constant_16_output_0 / _bert_encoder_layer_8_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_8_attention_self_Cast_1_output_0 = _bert_encoder_layer_8_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_8_attention_self_Transpose_2_output_0 = _bert_encoder_layer_8_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_8_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_8_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_8_attention_self_Mul_output_0 = _bert_encoder_layer_8_attention_self_Transpose_output_0 * _bert_encoder_layer_8_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_8_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_8_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_8_attention_self_Mul_1_output_0 = _bert_encoder_layer_8_attention_self_Transpose_2_output_0 * _bert_encoder_layer_8_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_8_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_8_attention_self_Mul_output_0, _bert_encoder_layer_8_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_8_attention_self_Add_output_0 = _bert_encoder_layer_8_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_8_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_8_attention_self_Add_output_0);
    auto _bert_encoder_layer_8_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_8_attention_self_Softmax_output_0, _bert_encoder_layer_8_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_8_attention_self_Transpose_3_output_0 = _bert_encoder_layer_8_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_8_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_1422>(_bert_encoder_layer_8_attention_self_Gather_output_0);
    auto _bert_encoder_layer_8_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_1424>(_bert_encoder_layer_8_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_8_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_8_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_8_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_8_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_8_attention_self_Reshape_3_output_0 = _bert_encoder_layer_8_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_8_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_8_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_8_attention_self_Reshape_3_output_0, onnx_MatMul_2013);
    auto _bert_encoder_layer_8_attention_output_dense_Add_output_0 = bert_encoder_layer_8_attention_output_dense_bias + _bert_encoder_layer_8_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_8_attention_output_Add_output_0 = _bert_encoder_layer_8_attention_output_dense_Add_output_0 + _bert_encoder_layer_7_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_8_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_8_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_8_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_8_attention_output_Add_output_0 - _bert_encoder_layer_8_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_8_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_8_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_8_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_8_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_8_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_8_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_8_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_8_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_8_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_8_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_8_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_8_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_8_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_8_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_8_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_8_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_8_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_8_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_8_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_8_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_8_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_2014);
    auto _bert_encoder_layer_8_intermediate_dense_Add_output_0 = bert_encoder_layer_8_intermediate_dense_bias + _bert_encoder_layer_8_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_8_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_8_intermediate_dense_Add_output_0 / _bert_encoder_layer_8_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_8_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_8_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_8_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_8_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_8_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_8_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_8_intermediate_dense_Add_output_0 * _bert_encoder_layer_8_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_8_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_8_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_8_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_8_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_8_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_2015);
    auto _bert_encoder_layer_8_output_dense_Add_output_0 = bert_encoder_layer_8_output_dense_bias + _bert_encoder_layer_8_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_8_output_Add_output_0 = _bert_encoder_layer_8_output_dense_Add_output_0 + _bert_encoder_layer_8_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_8_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_8_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_8_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_8_output_Add_output_0 - _bert_encoder_layer_8_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_8_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_8_output_LayerNorm_Sub_output_0, _bert_encoder_layer_8_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_8_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_8_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_8_output_LayerNorm_Add_output_0 = _bert_encoder_layer_8_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_8_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_8_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_8_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_8_output_LayerNorm_Div_output_0 = _bert_encoder_layer_8_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_8_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_8_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_8_output_LayerNorm_Div_output_0 * bert_encoder_layer_8_output_LayerNorm_weight;
    auto _bert_encoder_layer_8_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_8_output_LayerNorm_Mul_output_0 + bert_encoder_layer_8_output_LayerNorm_bias;
    auto _bert_encoder_layer_9_attention_self_Shape_output_0 = shape(_bert_encoder_layer_8_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_9_attention_self_Gather_output_0 = gather(_bert_encoder_layer_9_attention_self_Shape_output_0, _bert_encoder_layer_9_attention_self_Constant_output_0);
    auto _bert_encoder_layer_9_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_8_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_9_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_9_attention_self_Shape_1_output_0, _bert_encoder_layer_9_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_9_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_8_output_LayerNorm_Add_1_output_0, onnx_MatMul_2016);
    auto _bert_encoder_layer_9_attention_self_query_Add_output_0 = bert_encoder_layer_9_attention_self_query_bias + _bert_encoder_layer_9_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_9_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_9_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_9_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_9_attention_self_Shape_2_output_0, _bert_encoder_layer_9_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_9_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_9_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_9_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_9_attention_self_Shape_3_output_0, _bert_encoder_layer_9_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_9_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_1486>(_bert_encoder_layer_9_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_9_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_1488>(_bert_encoder_layer_9_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_9_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_9_attention_self_Unsqueeze_output_0, _bert_encoder_layer_9_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_9_attention_self_Constant_4_output_0, _bert_encoder_layer_9_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_9_attention_self_Reshape_output_0 = _bert_encoder_layer_9_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_9_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_9_attention_self_Transpose_output_0 = _bert_encoder_layer_9_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_9_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_8_output_LayerNorm_Add_1_output_0, onnx_MatMul_2019);
    auto _bert_encoder_layer_9_attention_self_key_Add_output_0 = bert_encoder_layer_9_attention_self_key_bias + _bert_encoder_layer_9_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_9_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_9_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_9_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_9_attention_self_Shape_4_output_0, _bert_encoder_layer_9_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_9_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_9_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_9_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_9_attention_self_Shape_5_output_0, _bert_encoder_layer_9_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_9_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_1506>(_bert_encoder_layer_9_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_9_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_1508>(_bert_encoder_layer_9_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_9_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_9_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_9_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_9_attention_self_Constant_8_output_0, _bert_encoder_layer_9_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_9_attention_self_Reshape_1_output_0 = _bert_encoder_layer_9_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_9_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_9_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_8_output_LayerNorm_Add_1_output_0, onnx_MatMul_2022);
    auto _bert_encoder_layer_9_attention_self_value_Add_output_0 = bert_encoder_layer_9_attention_self_value_bias + _bert_encoder_layer_9_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_9_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_9_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_9_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_9_attention_self_Shape_6_output_0, _bert_encoder_layer_9_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_9_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_9_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_9_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_9_attention_self_Shape_7_output_0, _bert_encoder_layer_9_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_9_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_1525>(_bert_encoder_layer_9_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_9_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_1527>(_bert_encoder_layer_9_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_9_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_9_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_9_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_9_attention_self_Constant_12_output_0, _bert_encoder_layer_9_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_9_attention_self_Reshape_2_output_0 = _bert_encoder_layer_9_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_9_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_9_attention_self_Transpose_1_output_0 = _bert_encoder_layer_9_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_9_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_9_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_9_attention_self_Slice_output_0 = _bert_encoder_layer_9_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_9_attention_self_Constant_14_output_0,_bert_encoder_layer_9_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_9_attention_self_Cast_output_0 = _bert_encoder_layer_9_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_9_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_9_attention_self_Cast_output_0);
    auto _bert_encoder_layer_9_attention_self_Div_output_0 = _bert_encoder_layer_9_attention_self_Constant_16_output_0 / _bert_encoder_layer_9_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_9_attention_self_Cast_1_output_0 = _bert_encoder_layer_9_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_9_attention_self_Transpose_2_output_0 = _bert_encoder_layer_9_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_9_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_9_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_9_attention_self_Mul_output_0 = _bert_encoder_layer_9_attention_self_Transpose_output_0 * _bert_encoder_layer_9_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_9_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_9_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_9_attention_self_Mul_1_output_0 = _bert_encoder_layer_9_attention_self_Transpose_2_output_0 * _bert_encoder_layer_9_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_9_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_9_attention_self_Mul_output_0, _bert_encoder_layer_9_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_9_attention_self_Add_output_0 = _bert_encoder_layer_9_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_9_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_9_attention_self_Add_output_0);
    auto _bert_encoder_layer_9_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_9_attention_self_Softmax_output_0, _bert_encoder_layer_9_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_9_attention_self_Transpose_3_output_0 = _bert_encoder_layer_9_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_9_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_1555>(_bert_encoder_layer_9_attention_self_Gather_output_0);
    auto _bert_encoder_layer_9_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_1557>(_bert_encoder_layer_9_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_9_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_9_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_9_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_9_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_9_attention_self_Reshape_3_output_0 = _bert_encoder_layer_9_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_9_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_9_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_9_attention_self_Reshape_3_output_0, onnx_MatMul_2026);
    auto _bert_encoder_layer_9_attention_output_dense_Add_output_0 = bert_encoder_layer_9_attention_output_dense_bias + _bert_encoder_layer_9_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_9_attention_output_Add_output_0 = _bert_encoder_layer_9_attention_output_dense_Add_output_0 + _bert_encoder_layer_8_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_9_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_9_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_9_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_9_attention_output_Add_output_0 - _bert_encoder_layer_9_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_9_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_9_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_9_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_9_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_9_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_9_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_9_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_9_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_9_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_9_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_9_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_9_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_9_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_9_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_9_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_9_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_9_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_9_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_9_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_9_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_9_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_2027);
    auto _bert_encoder_layer_9_intermediate_dense_Add_output_0 = bert_encoder_layer_9_intermediate_dense_bias + _bert_encoder_layer_9_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_9_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_9_intermediate_dense_Add_output_0 / _bert_encoder_layer_9_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_9_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_9_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_9_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_9_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_9_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_9_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_9_intermediate_dense_Add_output_0 * _bert_encoder_layer_9_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_9_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_9_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_9_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_9_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_9_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_2028);
    auto _bert_encoder_layer_9_output_dense_Add_output_0 = bert_encoder_layer_9_output_dense_bias + _bert_encoder_layer_9_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_9_output_Add_output_0 = _bert_encoder_layer_9_output_dense_Add_output_0 + _bert_encoder_layer_9_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_9_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_9_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_9_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_9_output_Add_output_0 - _bert_encoder_layer_9_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_9_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_9_output_LayerNorm_Sub_output_0, _bert_encoder_layer_9_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_9_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_9_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_9_output_LayerNorm_Add_output_0 = _bert_encoder_layer_9_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_9_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_9_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_9_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_9_output_LayerNorm_Div_output_0 = _bert_encoder_layer_9_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_9_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_9_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_9_output_LayerNorm_Div_output_0 * bert_encoder_layer_9_output_LayerNorm_weight;
    auto _bert_encoder_layer_9_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_9_output_LayerNorm_Mul_output_0 + bert_encoder_layer_9_output_LayerNorm_bias;
    auto _bert_encoder_layer_10_attention_self_Shape_output_0 = shape(_bert_encoder_layer_9_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_10_attention_self_Gather_output_0 = gather(_bert_encoder_layer_10_attention_self_Shape_output_0, _bert_encoder_layer_10_attention_self_Constant_output_0);
    auto _bert_encoder_layer_10_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_9_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_10_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_10_attention_self_Shape_1_output_0, _bert_encoder_layer_10_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_10_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_9_output_LayerNorm_Add_1_output_0, onnx_MatMul_2029);
    auto _bert_encoder_layer_10_attention_self_query_Add_output_0 = bert_encoder_layer_10_attention_self_query_bias + _bert_encoder_layer_10_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_10_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_10_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_10_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_10_attention_self_Shape_2_output_0, _bert_encoder_layer_10_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_10_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_10_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_10_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_10_attention_self_Shape_3_output_0, _bert_encoder_layer_10_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_10_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_1619>(_bert_encoder_layer_10_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_10_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_1621>(_bert_encoder_layer_10_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_10_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_10_attention_self_Unsqueeze_output_0, _bert_encoder_layer_10_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_10_attention_self_Constant_4_output_0, _bert_encoder_layer_10_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_10_attention_self_Reshape_output_0 = _bert_encoder_layer_10_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_10_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_10_attention_self_Transpose_output_0 = _bert_encoder_layer_10_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_10_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_9_output_LayerNorm_Add_1_output_0, onnx_MatMul_2032);
    auto _bert_encoder_layer_10_attention_self_key_Add_output_0 = bert_encoder_layer_10_attention_self_key_bias + _bert_encoder_layer_10_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_10_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_10_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_10_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_10_attention_self_Shape_4_output_0, _bert_encoder_layer_10_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_10_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_10_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_10_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_10_attention_self_Shape_5_output_0, _bert_encoder_layer_10_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_10_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_1639>(_bert_encoder_layer_10_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_10_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_1641>(_bert_encoder_layer_10_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_10_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_10_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_10_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_10_attention_self_Constant_8_output_0, _bert_encoder_layer_10_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_10_attention_self_Reshape_1_output_0 = _bert_encoder_layer_10_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_10_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_10_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_9_output_LayerNorm_Add_1_output_0, onnx_MatMul_2035);
    auto _bert_encoder_layer_10_attention_self_value_Add_output_0 = bert_encoder_layer_10_attention_self_value_bias + _bert_encoder_layer_10_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_10_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_10_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_10_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_10_attention_self_Shape_6_output_0, _bert_encoder_layer_10_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_10_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_10_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_10_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_10_attention_self_Shape_7_output_0, _bert_encoder_layer_10_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_10_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_1658>(_bert_encoder_layer_10_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_10_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_1660>(_bert_encoder_layer_10_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_10_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_10_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_10_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_10_attention_self_Constant_12_output_0, _bert_encoder_layer_10_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_10_attention_self_Reshape_2_output_0 = _bert_encoder_layer_10_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_10_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_10_attention_self_Transpose_1_output_0 = _bert_encoder_layer_10_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_10_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_10_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_10_attention_self_Slice_output_0 = _bert_encoder_layer_10_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_10_attention_self_Constant_14_output_0,_bert_encoder_layer_10_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_10_attention_self_Cast_output_0 = _bert_encoder_layer_10_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_10_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_10_attention_self_Cast_output_0);
    auto _bert_encoder_layer_10_attention_self_Div_output_0 = _bert_encoder_layer_10_attention_self_Constant_16_output_0 / _bert_encoder_layer_10_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_10_attention_self_Cast_1_output_0 = _bert_encoder_layer_10_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_10_attention_self_Transpose_2_output_0 = _bert_encoder_layer_10_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_10_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_10_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_10_attention_self_Mul_output_0 = _bert_encoder_layer_10_attention_self_Transpose_output_0 * _bert_encoder_layer_10_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_10_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_10_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_10_attention_self_Mul_1_output_0 = _bert_encoder_layer_10_attention_self_Transpose_2_output_0 * _bert_encoder_layer_10_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_10_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_10_attention_self_Mul_output_0, _bert_encoder_layer_10_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_10_attention_self_Add_output_0 = _bert_encoder_layer_10_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_10_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_10_attention_self_Add_output_0);
    auto _bert_encoder_layer_10_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_10_attention_self_Softmax_output_0, _bert_encoder_layer_10_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_10_attention_self_Transpose_3_output_0 = _bert_encoder_layer_10_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_10_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_1688>(_bert_encoder_layer_10_attention_self_Gather_output_0);
    auto _bert_encoder_layer_10_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_1690>(_bert_encoder_layer_10_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_10_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_10_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_10_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_10_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_10_attention_self_Reshape_3_output_0 = _bert_encoder_layer_10_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_10_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_10_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_10_attention_self_Reshape_3_output_0, onnx_MatMul_2039);
    auto _bert_encoder_layer_10_attention_output_dense_Add_output_0 = bert_encoder_layer_10_attention_output_dense_bias + _bert_encoder_layer_10_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_10_attention_output_Add_output_0 = _bert_encoder_layer_10_attention_output_dense_Add_output_0 + _bert_encoder_layer_9_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_10_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_10_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_10_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_10_attention_output_Add_output_0 - _bert_encoder_layer_10_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_10_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_10_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_10_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_10_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_10_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_10_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_10_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_10_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_10_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_10_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_10_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_10_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_10_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_10_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_10_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_10_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_10_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_10_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_10_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_10_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_10_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_2040);
    auto _bert_encoder_layer_10_intermediate_dense_Add_output_0 = bert_encoder_layer_10_intermediate_dense_bias + _bert_encoder_layer_10_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_10_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_10_intermediate_dense_Add_output_0 / _bert_encoder_layer_10_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_10_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_10_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_10_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_10_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_10_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_10_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_10_intermediate_dense_Add_output_0 * _bert_encoder_layer_10_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_10_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_10_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_10_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_10_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_10_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_2041);
    auto _bert_encoder_layer_10_output_dense_Add_output_0 = bert_encoder_layer_10_output_dense_bias + _bert_encoder_layer_10_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_10_output_Add_output_0 = _bert_encoder_layer_10_output_dense_Add_output_0 + _bert_encoder_layer_10_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_10_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_10_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_10_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_10_output_Add_output_0 - _bert_encoder_layer_10_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_10_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_10_output_LayerNorm_Sub_output_0, _bert_encoder_layer_10_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_10_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_10_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_10_output_LayerNorm_Add_output_0 = _bert_encoder_layer_10_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_10_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_10_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_10_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_10_output_LayerNorm_Div_output_0 = _bert_encoder_layer_10_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_10_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_10_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_10_output_LayerNorm_Div_output_0 * bert_encoder_layer_10_output_LayerNorm_weight;
    auto _bert_encoder_layer_10_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_10_output_LayerNorm_Mul_output_0 + bert_encoder_layer_10_output_LayerNorm_bias;
    auto _bert_encoder_layer_11_attention_self_Shape_output_0 = shape(_bert_encoder_layer_10_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_11_attention_self_Gather_output_0 = gather(_bert_encoder_layer_11_attention_self_Shape_output_0, _bert_encoder_layer_11_attention_self_Constant_output_0);
    auto _bert_encoder_layer_11_attention_self_Shape_1_output_0 = shape(_bert_encoder_layer_10_output_LayerNorm_Add_1_output_0);
    auto _bert_encoder_layer_11_attention_self_Gather_1_output_0 = gather(_bert_encoder_layer_11_attention_self_Shape_1_output_0, _bert_encoder_layer_11_attention_self_Constant_1_output_0);
    auto _bert_encoder_layer_11_attention_self_query_MatMul_output_0 = matmul<1>(_bert_encoder_layer_10_output_LayerNorm_Add_1_output_0, onnx_MatMul_2042);
    auto _bert_encoder_layer_11_attention_self_query_Add_output_0 = bert_encoder_layer_11_attention_self_query_bias + _bert_encoder_layer_11_attention_self_query_MatMul_output_0;
    auto _bert_encoder_layer_11_attention_self_Shape_2_output_0 = shape(_bert_encoder_layer_11_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_11_attention_self_Gather_2_output_0 = gather(_bert_encoder_layer_11_attention_self_Shape_2_output_0, _bert_encoder_layer_11_attention_self_Constant_2_output_0);
    auto _bert_encoder_layer_11_attention_self_Shape_3_output_0 = shape(_bert_encoder_layer_11_attention_self_query_Add_output_0);
    auto _bert_encoder_layer_11_attention_self_Gather_3_output_0 = gather(_bert_encoder_layer_11_attention_self_Shape_3_output_0, _bert_encoder_layer_11_attention_self_Constant_3_output_0);
    auto _bert_encoder_layer_11_attention_self_Unsqueeze_output_0 = unsqueeze<onnx_Unsqueeze_1752>(_bert_encoder_layer_11_attention_self_Gather_2_output_0);
    auto _bert_encoder_layer_11_attention_self_Unsqueeze_1_output_0 = unsqueeze<onnx_Unsqueeze_1754>(_bert_encoder_layer_11_attention_self_Gather_3_output_0);
    auto _bert_encoder_layer_11_attention_self_Concat_output_0 = concat<0>(_bert_encoder_layer_11_attention_self_Unsqueeze_output_0, _bert_encoder_layer_11_attention_self_Unsqueeze_1_output_0, _bert_encoder_layer_11_attention_self_Constant_4_output_0, _bert_encoder_layer_11_attention_self_Constant_5_output_0);
    auto _bert_encoder_layer_11_attention_self_Reshape_output_0 = _bert_encoder_layer_11_attention_self_query_Add_output_0.template reshape<_bert_encoder_layer_11_attention_self_Concat_output_0>();
    auto _bert_encoder_layer_11_attention_self_Transpose_output_0 = _bert_encoder_layer_11_attention_self_Reshape_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_11_attention_self_key_MatMul_output_0 = matmul<1>(_bert_encoder_layer_10_output_LayerNorm_Add_1_output_0, onnx_MatMul_2045);
    auto _bert_encoder_layer_11_attention_self_key_Add_output_0 = bert_encoder_layer_11_attention_self_key_bias + _bert_encoder_layer_11_attention_self_key_MatMul_output_0;
    auto _bert_encoder_layer_11_attention_self_Shape_4_output_0 = shape(_bert_encoder_layer_11_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_11_attention_self_Gather_4_output_0 = gather(_bert_encoder_layer_11_attention_self_Shape_4_output_0, _bert_encoder_layer_11_attention_self_Constant_6_output_0);
    auto _bert_encoder_layer_11_attention_self_Shape_5_output_0 = shape(_bert_encoder_layer_11_attention_self_key_Add_output_0);
    auto _bert_encoder_layer_11_attention_self_Gather_5_output_0 = gather(_bert_encoder_layer_11_attention_self_Shape_5_output_0, _bert_encoder_layer_11_attention_self_Constant_7_output_0);
    auto _bert_encoder_layer_11_attention_self_Unsqueeze_2_output_0 = unsqueeze<onnx_Unsqueeze_1772>(_bert_encoder_layer_11_attention_self_Gather_4_output_0);
    auto _bert_encoder_layer_11_attention_self_Unsqueeze_3_output_0 = unsqueeze<onnx_Unsqueeze_1774>(_bert_encoder_layer_11_attention_self_Gather_5_output_0);
    auto _bert_encoder_layer_11_attention_self_Concat_1_output_0 = concat<0>(_bert_encoder_layer_11_attention_self_Unsqueeze_2_output_0, _bert_encoder_layer_11_attention_self_Unsqueeze_3_output_0, _bert_encoder_layer_11_attention_self_Constant_8_output_0, _bert_encoder_layer_11_attention_self_Constant_9_output_0);
    auto _bert_encoder_layer_11_attention_self_Reshape_1_output_0 = _bert_encoder_layer_11_attention_self_key_Add_output_0.template reshape<_bert_encoder_layer_11_attention_self_Concat_1_output_0>();
    auto _bert_encoder_layer_11_attention_self_value_MatMul_output_0 = matmul<1>(_bert_encoder_layer_10_output_LayerNorm_Add_1_output_0, onnx_MatMul_2048);
    auto _bert_encoder_layer_11_attention_self_value_Add_output_0 = bert_encoder_layer_11_attention_self_value_bias + _bert_encoder_layer_11_attention_self_value_MatMul_output_0;
    auto _bert_encoder_layer_11_attention_self_Shape_6_output_0 = shape(_bert_encoder_layer_11_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_11_attention_self_Gather_6_output_0 = gather(_bert_encoder_layer_11_attention_self_Shape_6_output_0, _bert_encoder_layer_11_attention_self_Constant_10_output_0);
    auto _bert_encoder_layer_11_attention_self_Shape_7_output_0 = shape(_bert_encoder_layer_11_attention_self_value_Add_output_0);
    auto _bert_encoder_layer_11_attention_self_Gather_7_output_0 = gather(_bert_encoder_layer_11_attention_self_Shape_7_output_0, _bert_encoder_layer_11_attention_self_Constant_11_output_0);
    auto _bert_encoder_layer_11_attention_self_Unsqueeze_4_output_0 = unsqueeze<onnx_Unsqueeze_1791>(_bert_encoder_layer_11_attention_self_Gather_6_output_0);
    auto _bert_encoder_layer_11_attention_self_Unsqueeze_5_output_0 = unsqueeze<onnx_Unsqueeze_1793>(_bert_encoder_layer_11_attention_self_Gather_7_output_0);
    auto _bert_encoder_layer_11_attention_self_Concat_2_output_0 = concat<0>(_bert_encoder_layer_11_attention_self_Unsqueeze_4_output_0, _bert_encoder_layer_11_attention_self_Unsqueeze_5_output_0, _bert_encoder_layer_11_attention_self_Constant_12_output_0, _bert_encoder_layer_11_attention_self_Constant_13_output_0);
    auto _bert_encoder_layer_11_attention_self_Reshape_2_output_0 = _bert_encoder_layer_11_attention_self_value_Add_output_0.template reshape<_bert_encoder_layer_11_attention_self_Concat_2_output_0>();
    auto _bert_encoder_layer_11_attention_self_Transpose_1_output_0 = _bert_encoder_layer_11_attention_self_Reshape_2_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_11_attention_self_Shape_8_output_0 = shape(_bert_encoder_layer_11_attention_self_Transpose_output_0);
    auto _bert_encoder_layer_11_attention_self_Slice_output_0 = _bert_encoder_layer_11_attention_self_Shape_8_output_0.template slice<_bert_encoder_layer_11_attention_self_Constant_14_output_0,_bert_encoder_layer_11_attention_self_Constant_15_output_0>();
    auto _bert_encoder_layer_11_attention_self_Cast_output_0 = _bert_encoder_layer_11_attention_self_Slice_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_11_attention_self_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_11_attention_self_Cast_output_0);
    auto _bert_encoder_layer_11_attention_self_Div_output_0 = _bert_encoder_layer_11_attention_self_Constant_16_output_0 / _bert_encoder_layer_11_attention_self_Sqrt_output_0;
    auto _bert_encoder_layer_11_attention_self_Cast_1_output_0 = _bert_encoder_layer_11_attention_self_Div_output_0.template to<uint8_t>();
    auto _bert_encoder_layer_11_attention_self_Transpose_2_output_0 = _bert_encoder_layer_11_attention_self_Reshape_1_output_0.template transpose<0,2,3,1>();
    auto _bert_encoder_layer_11_attention_self_Sqrt_1_output_0 = sqrt<false>(_bert_encoder_layer_11_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_11_attention_self_Mul_output_0 = _bert_encoder_layer_11_attention_self_Transpose_output_0 * _bert_encoder_layer_11_attention_self_Sqrt_1_output_0;
    auto _bert_encoder_layer_11_attention_self_Sqrt_2_output_0 = sqrt<false>(_bert_encoder_layer_11_attention_self_Cast_1_output_0);
    auto _bert_encoder_layer_11_attention_self_Mul_1_output_0 = _bert_encoder_layer_11_attention_self_Transpose_2_output_0 * _bert_encoder_layer_11_attention_self_Sqrt_2_output_0;
    auto _bert_encoder_layer_11_attention_self_MatMul_output_0 = matmul<1>(_bert_encoder_layer_11_attention_self_Mul_output_0, _bert_encoder_layer_11_attention_self_Mul_1_output_0);
    auto _bert_encoder_layer_11_attention_self_Add_output_0 = _bert_encoder_layer_11_attention_self_MatMul_output_0 + _bert_Where_1_output_0;
    auto _bert_encoder_layer_11_attention_self_Softmax_output_0 = softmax<-1, true>(_bert_encoder_layer_11_attention_self_Add_output_0);
    auto _bert_encoder_layer_11_attention_self_MatMul_1_output_0 = matmul<1>(_bert_encoder_layer_11_attention_self_Softmax_output_0, _bert_encoder_layer_11_attention_self_Transpose_1_output_0);
    auto _bert_encoder_layer_11_attention_self_Transpose_3_output_0 = _bert_encoder_layer_11_attention_self_MatMul_1_output_0.template transpose<0,2,1,3>();
    auto _bert_encoder_layer_11_attention_self_Unsqueeze_6_output_0 = unsqueeze<onnx_Unsqueeze_1821>(_bert_encoder_layer_11_attention_self_Gather_output_0);
    auto _bert_encoder_layer_11_attention_self_Unsqueeze_7_output_0 = unsqueeze<onnx_Unsqueeze_1823>(_bert_encoder_layer_11_attention_self_Gather_1_output_0);
    auto _bert_encoder_layer_11_attention_self_Concat_3_output_0 = concat<0>(_bert_encoder_layer_11_attention_self_Unsqueeze_6_output_0, _bert_encoder_layer_11_attention_self_Unsqueeze_7_output_0, _bert_encoder_layer_11_attention_self_Constant_17_output_0);
    auto _bert_encoder_layer_11_attention_self_Reshape_3_output_0 = _bert_encoder_layer_11_attention_self_Transpose_3_output_0.template reshape<_bert_encoder_layer_11_attention_self_Concat_3_output_0>();
    auto _bert_encoder_layer_11_attention_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_11_attention_self_Reshape_3_output_0, onnx_MatMul_2052);
    auto _bert_encoder_layer_11_attention_output_dense_Add_output_0 = bert_encoder_layer_11_attention_output_dense_bias + _bert_encoder_layer_11_attention_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_11_attention_output_Add_output_0 = _bert_encoder_layer_11_attention_output_dense_Add_output_0 + _bert_encoder_layer_10_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_11_attention_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_11_attention_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_11_attention_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_11_attention_output_Add_output_0 - _bert_encoder_layer_11_attention_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_11_attention_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_11_attention_output_LayerNorm_Sub_output_0, _bert_encoder_layer_11_attention_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_11_attention_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_11_attention_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_11_attention_output_LayerNorm_Add_output_0 = _bert_encoder_layer_11_attention_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_11_attention_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_11_attention_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_11_attention_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_11_attention_output_LayerNorm_Div_output_0 = _bert_encoder_layer_11_attention_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_11_attention_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_11_attention_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_11_attention_output_LayerNorm_Div_output_0 * bert_encoder_layer_11_attention_output_LayerNorm_weight;
    auto _bert_encoder_layer_11_attention_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_11_attention_output_LayerNorm_Mul_output_0 + bert_encoder_layer_11_attention_output_LayerNorm_bias;
    auto _bert_encoder_layer_11_intermediate_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_11_attention_output_LayerNorm_Add_1_output_0, onnx_MatMul_2053);
    auto _bert_encoder_layer_11_intermediate_dense_Add_output_0 = bert_encoder_layer_11_intermediate_dense_bias + _bert_encoder_layer_11_intermediate_dense_MatMul_output_0;
    auto _bert_encoder_layer_11_intermediate_intermediate_act_fn_Div_output_0 = _bert_encoder_layer_11_intermediate_dense_Add_output_0 / _bert_encoder_layer_11_intermediate_intermediate_act_fn_Constant_output_0;
    auto _bert_encoder_layer_11_intermediate_intermediate_act_fn_Erf_output_0 = erf<true>(_bert_encoder_layer_11_intermediate_intermediate_act_fn_Div_output_0);
    auto _bert_encoder_layer_11_intermediate_intermediate_act_fn_Add_output_0 = _bert_encoder_layer_11_intermediate_intermediate_act_fn_Erf_output_0 + _bert_encoder_layer_11_intermediate_intermediate_act_fn_Constant_1_output_0;
    auto _bert_encoder_layer_11_intermediate_intermediate_act_fn_Mul_output_0 = _bert_encoder_layer_11_intermediate_dense_Add_output_0 * _bert_encoder_layer_11_intermediate_intermediate_act_fn_Add_output_0;
    auto _bert_encoder_layer_11_intermediate_intermediate_act_fn_Mul_1_output_0 = _bert_encoder_layer_11_intermediate_intermediate_act_fn_Mul_output_0 * _bert_encoder_layer_11_intermediate_intermediate_act_fn_Constant_2_output_0;
    auto _bert_encoder_layer_11_output_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_11_intermediate_intermediate_act_fn_Mul_1_output_0, onnx_MatMul_2054);
    auto _bert_encoder_layer_11_output_dense_Add_output_0 = bert_encoder_layer_11_output_dense_bias + _bert_encoder_layer_11_output_dense_MatMul_output_0;
    auto _bert_encoder_layer_11_output_Add_output_0 = _bert_encoder_layer_11_output_dense_Add_output_0 + _bert_encoder_layer_11_attention_output_LayerNorm_Add_1_output_0;
    auto _bert_encoder_layer_11_output_LayerNorm_ReduceMean_output_0 = _bert_encoder_layer_11_output_Add_output_0.template mean<0>();
    auto _bert_encoder_layer_11_output_LayerNorm_Sub_output_0 = _bert_encoder_layer_11_output_Add_output_0 - _bert_encoder_layer_11_output_LayerNorm_ReduceMean_output_0;
    auto _bert_encoder_layer_11_output_LayerNorm_Pow_output_0 = pow<false>(_bert_encoder_layer_11_output_LayerNorm_Sub_output_0, _bert_encoder_layer_11_output_LayerNorm_Constant_output_0);
    auto _bert_encoder_layer_11_output_LayerNorm_ReduceMean_1_output_0 = _bert_encoder_layer_11_output_LayerNorm_Pow_output_0.template mean<0>();
    auto _bert_encoder_layer_11_output_LayerNorm_Add_output_0 = _bert_encoder_layer_11_output_LayerNorm_ReduceMean_1_output_0 + _bert_encoder_layer_11_output_LayerNorm_Constant_1_output_0;
    auto _bert_encoder_layer_11_output_LayerNorm_Sqrt_output_0 = sqrt<true>(_bert_encoder_layer_11_output_LayerNorm_Add_output_0);
    auto _bert_encoder_layer_11_output_LayerNorm_Div_output_0 = _bert_encoder_layer_11_output_LayerNorm_Sub_output_0 / _bert_encoder_layer_11_output_LayerNorm_Sqrt_output_0;
    auto _bert_encoder_layer_11_output_LayerNorm_Mul_output_0 = _bert_encoder_layer_11_output_LayerNorm_Div_output_0 * bert_encoder_layer_11_output_LayerNorm_weight;
    auto _bert_encoder_layer_11_output_LayerNorm_Add_1_output_0 = _bert_encoder_layer_11_output_LayerNorm_Mul_output_0 + bert_encoder_layer_11_output_LayerNorm_bias;
    auto _cls_predictions_transform_dense_MatMul_output_0 = matmul<1>(_bert_encoder_layer_11_output_LayerNorm_Add_1_output_0, onnx_MatMul_2055);
    auto _cls_predictions_transform_dense_Add_output_0 = cls_predictions_transform_dense_bias + _cls_predictions_transform_dense_MatMul_output_0;
    auto _cls_predictions_transform_transform_act_fn_Div_output_0 = _cls_predictions_transform_dense_Add_output_0 / _cls_predictions_transform_transform_act_fn_Constant_output_0;
    auto _cls_predictions_transform_transform_act_fn_Erf_output_0 = erf<true>(_cls_predictions_transform_transform_act_fn_Div_output_0);
    auto _cls_predictions_transform_transform_act_fn_Add_output_0 = _cls_predictions_transform_transform_act_fn_Erf_output_0 + _cls_predictions_transform_transform_act_fn_Constant_1_output_0;
    auto _cls_predictions_transform_transform_act_fn_Mul_output_0 = _cls_predictions_transform_dense_Add_output_0 * _cls_predictions_transform_transform_act_fn_Add_output_0;
    auto _cls_predictions_transform_transform_act_fn_Mul_1_output_0 = _cls_predictions_transform_transform_act_fn_Mul_output_0 * _cls_predictions_transform_transform_act_fn_Constant_2_output_0;
    auto _cls_predictions_transform_LayerNorm_ReduceMean_output_0 = _cls_predictions_transform_transform_act_fn_Mul_1_output_0.template mean<0>();
    auto _cls_predictions_transform_LayerNorm_Sub_output_0 = _cls_predictions_transform_transform_act_fn_Mul_1_output_0 - _cls_predictions_transform_LayerNorm_ReduceMean_output_0;
    auto _cls_predictions_transform_LayerNorm_Pow_output_0 = pow<false>(_cls_predictions_transform_LayerNorm_Sub_output_0, _cls_predictions_transform_LayerNorm_Constant_output_0);
    auto _cls_predictions_transform_LayerNorm_ReduceMean_1_output_0 = _cls_predictions_transform_LayerNorm_Pow_output_0.template mean<0>();
    auto _cls_predictions_transform_LayerNorm_Add_output_0 = _cls_predictions_transform_LayerNorm_ReduceMean_1_output_0 + _cls_predictions_transform_LayerNorm_Constant_1_output_0;
    auto _cls_predictions_transform_LayerNorm_Sqrt_output_0 = sqrt<true>(_cls_predictions_transform_LayerNorm_Add_output_0);
    auto _cls_predictions_transform_LayerNorm_Div_output_0 = _cls_predictions_transform_LayerNorm_Sub_output_0 / _cls_predictions_transform_LayerNorm_Sqrt_output_0;
    auto _cls_predictions_transform_LayerNorm_Mul_output_0 = _cls_predictions_transform_LayerNorm_Div_output_0 * cls_predictions_transform_LayerNorm_weight;
    auto _cls_predictions_transform_LayerNorm_Add_1_output_0 = _cls_predictions_transform_LayerNorm_Mul_output_0 + cls_predictions_transform_LayerNorm_bias;
    auto bert_embeddings_word_embeddings_weight_transposed = bert_embeddings_word_embeddings_weight.template transpose<>();
    auto _cls_predictions_decoder_MatMul_output_0 = matmul<1>(_cls_predictions_transform_LayerNorm_Add_1_output_0, bert_embeddings_word_embeddings_weight_transposed);
    auto logits = cls_predictions_bias + _cls_predictions_decoder_MatMul_output_0;
    return logits;
}};

